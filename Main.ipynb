{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwbxLv8DrmPsdZxwO4tu65"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEvTRtNnDY2Q",
        "outputId": "20914a30-c05c-4221-bdac-8085a658c09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS-3010-Final'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 80 (delta 27), reused 61 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (80/80), 16.16 MiB | 14.63 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/afrenkai/DS-3010-Final.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DS-3010-Final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiUGv3JMDiIb",
        "outputId": "ffd15eb2-ae0e-4d9d-9937-c69ad3ef9197"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DS-3010-Final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Exc780BDznq",
        "outputId": "ff8bc684-6aff-426e-b0cb-e19d7a800748"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balls.pth  data.ipynb  main.py\t\t    requirements.txt\n",
            "cv.py\t   LICENSE     Preprocessing.ipynb  setup.bat\n",
            "Data\t   Main.ipynb  README.md\t    sgemm_product.csv\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.13.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import lightgbm as lgb\n",
        "\n",
        "import torcheval.metrics as tm"
      ],
      "metadata": {
        "id": "KjqLGK9uDuvW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('Data/SGEMM_train.csv')\n",
        "val_df = pd.read_csv('Data/SGEMM_val.csv')"
      ],
      "metadata": {
        "id": "jSFtZgO5EIYi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "yFsL0jLPEah0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x, xmin, xmax, a, b):\n",
        "  '''\n",
        "  Restricts x values to range of [xmin, xmax]\n",
        "  '''\n",
        "  numerator = x - xmin\n",
        "  denominator = xmax - xmin\n",
        "  return (numerator / denominator) * (b - a) + a"
      ],
      "metadata": {
        "id": "VeZMpJ4fWVnS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_combine = ['Run1 (ms)', 'Run2 (ms)', 'Run3 (ms)', 'Run4 (ms)']"
      ],
      "metadata": {
        "id": "Zg8_iVh1EoPf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame):\n",
        "  df['DELTA_RUNTIME'] = df.apply(\n",
        "      lambda row: np.mean([row['Run1 (ms)'], row['Run2 (ms)'], row['Run3 (ms)'], row['Run4 (ms)']]),\n",
        "      axis=1\n",
        "  )\n",
        "  for col in df.columns:\n",
        "    if col in cols_to_combine:\n",
        "      df = df.drop(col, axis = 1)\n",
        "  min = 0\n",
        "  max = 1\n",
        "\n",
        "\n",
        "  df = df.apply(\n",
        "      lambda row: (norm(row, row.min(), row.max(), min, max))\n",
        "  )\n",
        "  x = df.iloc[:, :14]\n",
        "  y = df.iloc[:, -1:]\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "t7Ldc6DaEWb5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXYcVqELKyXo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "DsGLn9WEE1Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "x_tr, y_tr = preprocess(train_df)\n",
        "\n",
        "train_data = lgb.Dataset(x_tr, label=y_tr)\n",
        "x_val, y_val = preprocess(val_df)\n",
        "# Create a LightGBM dataset for testing with features X_val and labels Y_val,\n",
        "# and specify the reference dataset as train_data for consistent evaluation\n",
        "val_data = lgb.Dataset(x_val, label=y_val, reference=train_data)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "}\n",
        "\n",
        "num_round = 100\n",
        "bst = lgb.train(params, train_data, num_round, valid_sets=[\n",
        "                val_data])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Create an instance of the LightGBM Regressor with the RMSE metric.\n",
        "model = LGBMRegressor(metric='mse')\n",
        "\n",
        "# Train the model using the training data.\n",
        "model.fit(x_tr, y_tr)\n",
        "\n",
        "y_train = model.predict(x_tr)\n",
        "y_v = model.predict(x_val)\n",
        "print(\"Training MSE:\", mse(y_tr, y_train))\n",
        "print(\"Validation MSE:\", mse(y_val, y_v))\n",
        "\n",
        "print('train r2:', r2_score(y_tr, y_train))\n",
        "print('val r2:', r2_score(y_val, y_v))"
      ],
      "metadata": {
        "id": "bWXyH5z-Lmnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04d4a26-9c0f-4c33-b4a0-1132676f9362"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009292 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 40\n",
            "[LightGBM] [Info] Number of data points in the train set: 193280, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.061354\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 40\n",
            "[LightGBM] [Info] Number of data points in the train set: 193280, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.061354\n",
            "Training MSE: 0.00012048252219381041\n",
            "Validation MSE: 0.0001191615359407208\n",
            "train r2: 0.9901529624802171\n",
            "val r2: 0.9903041142135522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "7Aloer5wIPIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Want to predict Delta_Runtime via random forest\n",
        "X = train_df.drop('DELTA_RUNTIME', axis=1)\n",
        "y = train_df['DELTA_RUNTIME']\n",
        "\n",
        "\n",
        "#Create Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=69, verbose = 1, n_jobs = 16)\n",
        "#Fit Random Forest\n",
        "rf.fit(X, y)\n",
        "#See validation error based on validation set\n",
        "y_pred = rf.predict(val_df.drop('DELTA_RUNTIME', axis=1))\n",
        "mse = mean_squared_error(val_df['DELTA_RUNTIME'], y_pred)\n",
        "print(f'Validation MSE: {mse}')\n",
        "#Use CV to find best random forest\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w1Y84QV_IOw4",
        "outputId": "527dbc3c-f8a8-46f4-860d-315ca1f2dd4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
            "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   48.1s\n",
            "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
            "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
            "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 0.14641877729097943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Net"
      ],
      "metadata": {
        "id": "GKjUYgsALmtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPUNN(nn.Module):\n",
        "  def __init__(self, in_feat, out_feat):\n",
        "    super(GPUNN, self).__init__()\n",
        "    self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "    self.L1 = nn.Linear(in_feat, 64, device=self.device)\n",
        "    self.L2 = nn.Linear(64, out_feat, device = self.device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(64, device = self.device)\n",
        "    self.bn2 = nn.BatchNorm1d(out_feat, device = self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.relu(self.L1(x)))\n",
        "    x = self.bn2(self.L2(x))\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "TJtfhd5sLoz2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, train_dl: DataLoader, batch_size, device, n_epochs, optimizer, criterion):\n",
        "  model.train()\n",
        "  for batch, (data, target) in enumerate(train_dl):\n",
        "\n",
        "    data, target = data.to(device).float(), target.to(device).float()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                n_epochs, batch * len(data), len(train_dl.dataset),\n",
        "                100. * batch / len(train_dl), loss.item()))\n",
        "\n",
        "  torch.save(model.state_dict(), 'balls.pth')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jrBA-CHTOLEl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    losses = []\n",
        "    r2s = []\n",
        "    r2 = tm.R2Score().to(device)\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device).float(), target.to(device).float()\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "            losses.append(test_loss)\n",
        "            r2 = tm.R2Score()\n",
        "            r2.update(output, target)\n",
        "        r2s.append(r2.compute())\n",
        "    # print(test_loss / len(test_loader.dataset))\n",
        "    print(type(r2s[0].detach().cpu().numpy()))\n",
        "    return (np.mean([ten.detach().cpu().numpy() for ten in losses]), r2s)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-NN3jSkBVjKt"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dls(x: pd.DataFrame, y:pd.DataFrame):\n",
        "  x = x.loc[:, :].values\n",
        "  y = y.loc[:, :].values\n",
        "  x_ten = torch.tensor(x)\n",
        "  y_ten = torch.tensor(y)\n",
        "  ds = TensorDataset(x_ten, y_ten)\n",
        "  dl = DataLoader(ds, batch_size = 32)\n",
        "  return ds, dl"
      ],
      "metadata": {
        "id": "8ZQiw6qdP-5v"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, y_tr = preprocess(train_df)\n",
        "model = GPUNN(len(x_tr.columns), len(y_tr.columns))\n",
        "print(model)\n",
        "_, train_dl = create_dls(x_tr, y_tr)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
        "train(model, train_dl, 32, model.device, 10, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8nqyTzNkF6",
        "outputId": "7ebd4c8d-b941-47f0-911b-31976ce6fc01"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUNN(\n",
            "  (L1): Linear(in_features=14, out_features=64, bias=True)\n",
            "  (L2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "Train Epoch: 10 [0/193280 (0%)]\tLoss: 0.995820\n",
            "Train Epoch: 10 [3200/193280 (2%)]\tLoss: 0.937860\n",
            "Train Epoch: 10 [6400/193280 (3%)]\tLoss: 0.940761\n",
            "Train Epoch: 10 [9600/193280 (5%)]\tLoss: 0.907395\n",
            "Train Epoch: 10 [12800/193280 (7%)]\tLoss: 0.854515\n",
            "Train Epoch: 10 [16000/193280 (8%)]\tLoss: 0.774656\n",
            "Train Epoch: 10 [19200/193280 (10%)]\tLoss: 0.706388\n",
            "Train Epoch: 10 [22400/193280 (12%)]\tLoss: 0.755799\n",
            "Train Epoch: 10 [25600/193280 (13%)]\tLoss: 0.776572\n",
            "Train Epoch: 10 [28800/193280 (15%)]\tLoss: 0.707011\n",
            "Train Epoch: 10 [32000/193280 (17%)]\tLoss: 0.740380\n",
            "Train Epoch: 10 [35200/193280 (18%)]\tLoss: 0.674251\n",
            "Train Epoch: 10 [38400/193280 (20%)]\tLoss: 0.698263\n",
            "Train Epoch: 10 [41600/193280 (22%)]\tLoss: 0.649767\n",
            "Train Epoch: 10 [44800/193280 (23%)]\tLoss: 0.643496\n",
            "Train Epoch: 10 [48000/193280 (25%)]\tLoss: 0.599566\n",
            "Train Epoch: 10 [51200/193280 (26%)]\tLoss: 0.670563\n",
            "Train Epoch: 10 [54400/193280 (28%)]\tLoss: 0.615000\n",
            "Train Epoch: 10 [57600/193280 (30%)]\tLoss: 0.493215\n",
            "Train Epoch: 10 [60800/193280 (31%)]\tLoss: 0.589805\n",
            "Train Epoch: 10 [64000/193280 (33%)]\tLoss: 0.580040\n",
            "Train Epoch: 10 [67200/193280 (35%)]\tLoss: 0.446837\n",
            "Train Epoch: 10 [70400/193280 (36%)]\tLoss: 0.589664\n",
            "Train Epoch: 10 [73600/193280 (38%)]\tLoss: 0.431660\n",
            "Train Epoch: 10 [76800/193280 (40%)]\tLoss: 0.504095\n",
            "Train Epoch: 10 [80000/193280 (41%)]\tLoss: 0.456477\n",
            "Train Epoch: 10 [83200/193280 (43%)]\tLoss: 0.507638\n",
            "Train Epoch: 10 [86400/193280 (45%)]\tLoss: 0.406574\n",
            "Train Epoch: 10 [89600/193280 (46%)]\tLoss: 0.355201\n",
            "Train Epoch: 10 [92800/193280 (48%)]\tLoss: 0.342208\n",
            "Train Epoch: 10 [96000/193280 (50%)]\tLoss: 0.368440\n",
            "Train Epoch: 10 [99200/193280 (51%)]\tLoss: 0.441684\n",
            "Train Epoch: 10 [102400/193280 (53%)]\tLoss: 0.422491\n",
            "Train Epoch: 10 [105600/193280 (55%)]\tLoss: 0.374049\n",
            "Train Epoch: 10 [108800/193280 (56%)]\tLoss: 0.329956\n",
            "Train Epoch: 10 [112000/193280 (58%)]\tLoss: 0.409523\n",
            "Train Epoch: 10 [115200/193280 (60%)]\tLoss: 0.328460\n",
            "Train Epoch: 10 [118400/193280 (61%)]\tLoss: 0.327863\n",
            "Train Epoch: 10 [121600/193280 (63%)]\tLoss: 0.324251\n",
            "Train Epoch: 10 [124800/193280 (65%)]\tLoss: 0.387086\n",
            "Train Epoch: 10 [128000/193280 (66%)]\tLoss: 0.313962\n",
            "Train Epoch: 10 [131200/193280 (68%)]\tLoss: 0.302983\n",
            "Train Epoch: 10 [134400/193280 (70%)]\tLoss: 0.308157\n",
            "Train Epoch: 10 [137600/193280 (71%)]\tLoss: 0.204225\n",
            "Train Epoch: 10 [140800/193280 (73%)]\tLoss: 0.301006\n",
            "Train Epoch: 10 [144000/193280 (75%)]\tLoss: 0.297541\n",
            "Train Epoch: 10 [147200/193280 (76%)]\tLoss: 0.299045\n",
            "Train Epoch: 10 [150400/193280 (78%)]\tLoss: 0.188031\n",
            "Train Epoch: 10 [153600/193280 (79%)]\tLoss: 0.185821\n",
            "Train Epoch: 10 [156800/193280 (81%)]\tLoss: 0.173864\n",
            "Train Epoch: 10 [160000/193280 (83%)]\tLoss: 0.181618\n",
            "Train Epoch: 10 [163200/193280 (84%)]\tLoss: 0.241255\n",
            "Train Epoch: 10 [166400/193280 (86%)]\tLoss: 0.207611\n",
            "Train Epoch: 10 [169600/193280 (88%)]\tLoss: 0.193153\n",
            "Train Epoch: 10 [172800/193280 (89%)]\tLoss: 0.213675\n",
            "Train Epoch: 10 [176000/193280 (91%)]\tLoss: 0.212132\n",
            "Train Epoch: 10 [179200/193280 (93%)]\tLoss: 0.104960\n",
            "Train Epoch: 10 [182400/193280 (94%)]\tLoss: 0.160358\n",
            "Train Epoch: 10 [185600/193280 (96%)]\tLoss: 0.171662\n",
            "Train Epoch: 10 [188800/193280 (98%)]\tLoss: 0.173136\n",
            "Train Epoch: 10 [192000/193280 (99%)]\tLoss: 0.153334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, y_val = preprocess(val_df)\n",
        "_, val_dl = create_dls(x_val, y_val)\n",
        "criterion = nn.MSELoss()\n",
        "print(f'Neural Network Validation Mean Squared Error: {test(model, model.device, val_dl, criterion)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZcQqEQV7BA",
        "outputId": "1cf572bf-4582-4119-b307-2a3c956f5094"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Neural Network Validation Mean Squared Error: (np.float32(0.13344504), [tensor(-13.4533, device='cuda:0')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('balls.pth', weights_only=True))\n",
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "model.state_dict()"
      ],
      "metadata": {
        "id": "mOYlwVqjXoMV",
        "outputId": "2674ca3c-e0d8-49ca-d22a-9660c43b4a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('L1.weight',\n",
              "              tensor([[-1.8914e-03,  2.3810e-01,  8.4527e-02,  1.7204e-01, -2.5414e-01,\n",
              "                       -4.6591e-03,  1.2225e-01, -6.8267e-02,  6.5934e-04, -2.4809e-01,\n",
              "                       -1.1737e-01, -7.3755e-02,  1.4262e-01,  1.5098e-01],\n",
              "                      [ 1.1689e-01,  4.6500e-02, -2.2184e-01,  3.0327e-02,  1.1563e-01,\n",
              "                       -8.3968e-02,  2.7062e-01, -1.7804e-01,  1.6714e-01,  2.2119e-01,\n",
              "                       -2.0030e-01, -8.6430e-02, -1.6962e-01, -1.8974e-01],\n",
              "                      [ 1.1384e-01, -1.8544e-01,  1.5184e-01,  1.4528e-01, -1.1466e-01,\n",
              "                        2.2361e-01, -1.6375e-01,  1.7745e-01,  9.2666e-02,  2.4153e-01,\n",
              "                       -2.6441e-02, -1.9462e-01, -1.8542e-01,  3.3772e-02],\n",
              "                      [-5.4599e-03, -2.0889e-01, -1.4373e-02,  1.0746e-01, -1.9390e-01,\n",
              "                        1.4463e-02,  2.2057e-01,  1.9347e-01, -2.7768e-01,  2.4790e-01,\n",
              "                       -2.0094e-01, -1.1623e-01, -1.2318e-02, -5.6080e-03],\n",
              "                      [ 7.8186e-02,  2.4421e-01,  7.5105e-02,  8.7214e-02, -4.6383e-01,\n",
              "                        7.6151e-02, -1.5929e-01,  5.4609e-02,  1.4768e-01, -3.2873e-02,\n",
              "                       -3.8094e-02,  1.6356e-03,  6.2946e-02, -2.9746e-02],\n",
              "                      [ 2.6600e-01,  7.0290e-02, -6.5866e-02, -2.2176e-01, -1.9662e-01,\n",
              "                       -7.9591e-02, -1.7344e-01, -8.9141e-02,  7.3053e-02,  4.9838e-03,\n",
              "                       -2.2564e-01,  9.1840e-03, -2.0658e-01, -2.0294e-01],\n",
              "                      [ 1.6370e-01,  1.0690e-01, -2.5154e-02,  6.5898e-02,  2.3426e-01,\n",
              "                       -8.5901e-02, -2.2245e-01,  2.9223e-03, -4.2851e-03, -5.9747e-03,\n",
              "                       -2.1247e-01, -1.2197e-01, -1.5759e-01, -1.2790e-01],\n",
              "                      [ 4.2385e-02,  2.5343e-01,  1.5989e-01, -3.5690e-03, -1.2294e-01,\n",
              "                        1.4408e-01, -1.2488e-02,  1.7409e-01,  8.2799e-02,  1.6267e-01,\n",
              "                        1.9608e-01,  2.4206e-01,  1.0613e-01,  2.4396e-01],\n",
              "                      [ 2.5919e-01, -2.5358e-01,  6.4505e-02,  1.7303e-01,  8.9518e-02,\n",
              "                       -6.3641e-02,  2.1562e-01, -1.2283e-01,  2.5822e-01, -3.4823e-02,\n",
              "                        1.8952e-01,  1.3413e-01,  4.1547e-02,  1.0745e-02],\n",
              "                      [ 2.4143e-01, -1.4091e-01,  2.5528e-01,  6.5824e-02, -2.6044e-01,\n",
              "                        1.6003e-01,  1.0064e-01, -2.9211e-02,  8.7194e-02, -1.7924e-01,\n",
              "                        5.8635e-02,  3.7747e-02, -1.0843e-01,  1.3808e-01],\n",
              "                      [ 1.1799e-01, -2.3887e-01, -2.3985e-01, -1.3129e-02, -2.3646e-01,\n",
              "                       -2.0098e-01, -1.6260e-01, -1.2038e-01, -1.1641e-01,  1.1125e-01,\n",
              "                        6.7351e-02,  2.0936e-02, -4.5911e-02,  2.2933e-01],\n",
              "                      [-5.5341e-02, -1.4203e-01, -2.2448e-01,  7.4831e-02,  7.1087e-02,\n",
              "                       -4.3246e-02,  3.8130e-03,  1.4040e-01, -1.0457e-01,  1.6029e-01,\n",
              "                       -9.6423e-02,  7.5075e-02, -1.3106e-01,  1.1250e-01],\n",
              "                      [ 7.6751e-02,  7.5202e-02, -1.0497e-01, -8.1794e-02,  2.8669e-01,\n",
              "                        2.2547e-01, -2.4910e-01,  1.6543e-01, -1.8643e-01,  1.1064e-01,\n",
              "                       -7.0603e-02,  1.0527e-01,  2.6083e-01, -2.6588e-01],\n",
              "                      [ 3.2829e-02, -1.5344e-01,  4.6892e-02,  2.0146e-01, -3.2088e-02,\n",
              "                        1.9132e-01,  2.6114e-02, -6.2348e-02, -2.7068e-01,  1.7875e-01,\n",
              "                       -1.2643e-01, -1.3357e-01, -2.1455e-01,  1.4867e-02],\n",
              "                      [ 1.3729e-01,  2.1172e-01,  2.3231e-02,  1.9693e-01,  2.5527e-01,\n",
              "                        8.2352e-02, -1.1177e-01, -4.0511e-02,  2.9389e-02, -2.2158e-01,\n",
              "                        7.0191e-02,  7.7090e-02, -1.5402e-01,  1.6724e-01],\n",
              "                      [ 1.0813e-01,  1.0759e-01, -4.9647e-02,  1.6824e-01, -1.1181e-01,\n",
              "                       -1.4942e-01,  1.8000e-01, -1.6322e-01,  1.3245e-01,  1.9730e-01,\n",
              "                        6.6285e-02,  1.3118e-03, -1.7108e-01,  1.0550e-01],\n",
              "                      [-2.5685e-01, -2.3035e-01, -2.1585e-01, -1.6303e-01, -1.4960e-01,\n",
              "                       -6.4588e-02,  1.1898e-01, -1.9659e-01, -7.5764e-02,  1.2633e-01,\n",
              "                        8.1940e-02,  4.3194e-02, -1.2311e-01,  2.5943e-01],\n",
              "                      [ 7.5786e-02,  2.3802e-01, -2.4842e-01, -1.4035e-02, -3.1380e-01,\n",
              "                        2.0041e-01, -7.6822e-02,  1.0651e-01,  6.5971e-02,  1.7343e-01,\n",
              "                       -1.3262e-02,  1.8336e-01,  4.6719e-02,  2.0859e-01],\n",
              "                      [ 2.7999e-01, -1.6989e-01, -2.1176e-01,  6.0882e-02, -2.3957e-01,\n",
              "                        2.5512e-01,  7.3304e-02,  2.3849e-01,  2.0599e-01,  2.8854e-02,\n",
              "                        2.5659e-01, -3.3765e-02, -1.7460e-01, -1.3798e-01],\n",
              "                      [ 2.0876e-02, -6.4147e-02,  1.3107e-01,  1.5535e-01, -2.0923e-02,\n",
              "                       -4.9302e-02,  7.3807e-02,  2.4054e-01, -4.1338e-02,  1.5269e-01,\n",
              "                        1.9410e-01,  1.2450e-01,  1.7469e-01,  6.3335e-02],\n",
              "                      [-1.5807e-01, -1.5110e-01,  1.4014e-02, -3.7873e-02, -1.3059e-01,\n",
              "                       -9.3157e-02,  2.3488e-01, -1.6478e-01, -1.5223e-01, -1.8052e-01,\n",
              "                       -1.6340e-01,  9.3041e-02, -2.5536e-01, -1.9635e-01],\n",
              "                      [-1.7360e-01, -1.7016e-01,  9.9744e-02,  5.3942e-02, -1.5899e-01,\n",
              "                        1.8794e-01,  2.6376e-01,  2.4667e-01, -1.1906e-01,  1.4373e-01,\n",
              "                       -2.6763e-01, -2.1530e-02,  3.9575e-02,  1.9869e-01],\n",
              "                      [ 2.1829e-01, -7.8749e-02,  2.2202e-01,  1.8348e-01, -9.3020e-02,\n",
              "                        1.4294e-01,  1.4514e-01, -1.4494e-01, -6.6061e-03, -1.1426e-01,\n",
              "                       -8.6884e-02, -9.4649e-02, -6.5042e-02,  1.6690e-01],\n",
              "                      [-1.5363e-01,  6.9271e-02,  1.1808e-01,  2.6844e-01, -2.7530e-01,\n",
              "                        1.4466e-01, -1.2206e-01, -4.1984e-02,  2.7378e-01, -3.6838e-02,\n",
              "                       -1.5614e-02, -4.8579e-02, -1.0852e-02, -2.2295e-01],\n",
              "                      [-9.6771e-02, -1.7108e-01, -6.7888e-03, -1.1057e-01, -1.6416e-01,\n",
              "                       -7.9273e-02, -1.2753e-01,  1.0687e-01,  1.7740e-01, -2.0624e-02,\n",
              "                       -1.5801e-01, -5.6331e-02, -1.0299e-01, -9.7725e-02],\n",
              "                      [ 2.6650e-01,  9.9112e-02, -1.4267e-02, -1.5589e-01, -2.4742e-02,\n",
              "                       -3.4205e-02, -4.6612e-02,  1.9159e-01, -4.6469e-03,  7.6153e-02,\n",
              "                       -9.4406e-02, -2.2593e-01, -1.3776e-01,  2.1485e-01],\n",
              "                      [-1.8357e-01, -7.8577e-02, -7.1191e-03, -2.2432e-01,  2.5122e-01,\n",
              "                       -1.0275e-01, -2.1232e-01,  2.8227e-02, -5.3976e-02,  2.6107e-03,\n",
              "                       -1.0941e-01, -1.6778e-01, -1.6916e-01,  1.7723e-01],\n",
              "                      [ 1.8973e-01,  1.8133e-01,  3.2314e-02, -3.3008e-01, -2.8737e-01,\n",
              "                       -1.0263e-02, -5.9081e-04,  2.0105e-02, -9.2951e-03, -7.4790e-04,\n",
              "                        2.6764e-03,  1.8844e-03,  4.3739e-02,  4.0877e-02],\n",
              "                      [-7.4132e-02,  4.7460e-02, -1.5738e-01, -2.2176e-01, -2.1157e-01,\n",
              "                        2.5501e-01, -1.0566e-01, -7.0672e-03,  7.5819e-02, -1.8639e-01,\n",
              "                        1.4043e-01, -6.7965e-02, -1.8652e-01, -5.5177e-02],\n",
              "                      [-1.9531e-01, -5.0416e-02, -5.4420e-02,  2.7538e-01, -1.8389e-01,\n",
              "                        2.3347e-01,  2.1377e-01,  1.6196e-01, -2.7159e-01,  1.4426e-02,\n",
              "                        1.7318e-01,  1.8256e-01,  1.1787e-01, -1.8548e-01],\n",
              "                      [-2.7221e-01, -3.6475e-02,  1.4853e-01,  2.9144e-01,  8.2516e-02,\n",
              "                       -9.8650e-02, -1.9717e-01,  2.0802e-01,  8.3655e-02, -4.9798e-02,\n",
              "                        2.4965e-01, -5.8368e-02, -6.5678e-02,  8.7393e-02],\n",
              "                      [ 1.4532e-01,  1.0884e-01,  1.4857e-01, -2.2419e-02, -2.7074e-01,\n",
              "                       -1.7201e-01,  2.4167e-01, -1.8774e-01, -8.2268e-02,  6.4780e-02,\n",
              "                       -2.2107e-01,  5.0505e-02,  1.7170e-01,  3.2955e-02],\n",
              "                      [ 2.6968e-01,  1.7227e-01, -1.7624e-02, -1.1942e-02,  1.6671e-01,\n",
              "                       -6.3140e-02,  2.4174e-01, -2.0030e-01,  1.8549e-01,  2.1644e-01,\n",
              "                       -9.0983e-02,  1.1943e-01, -1.7712e-01, -2.5962e-02],\n",
              "                      [-1.9131e-01,  2.7741e-01, -7.7230e-02,  8.3022e-02,  5.4496e-03,\n",
              "                       -7.4360e-02, -2.2081e-01,  1.9753e-01,  1.8834e-02, -2.3126e-02,\n",
              "                        6.2726e-03, -1.5666e-01,  6.5583e-02, -1.6716e-01],\n",
              "                      [-8.6463e-02, -1.4333e-01, -1.6938e-01, -1.1979e-01,  1.8271e-01,\n",
              "                       -2.7199e-01, -1.2965e-01, -2.0968e-01, -7.9885e-02,  1.0926e-01,\n",
              "                       -2.8601e-02, -2.3923e-01,  1.7963e-01, -4.6323e-02],\n",
              "                      [-1.1347e-01,  8.8533e-02, -6.3299e-02,  1.4110e-01, -1.7089e-02,\n",
              "                       -2.3393e-01,  1.7289e-01, -1.1198e-01,  1.3061e-01, -1.5704e-01,\n",
              "                       -1.1325e-01, -1.7034e-01, -1.8123e-01, -2.5019e-01],\n",
              "                      [ 2.9688e-02,  1.5948e-01, -3.8123e-03,  2.2590e-01, -3.2032e-02,\n",
              "                        1.6882e-01,  2.4224e-01,  8.2903e-02,  1.1411e-01, -1.0332e-01,\n",
              "                       -1.0499e-01, -1.1633e-01,  7.6697e-02,  1.8950e-01],\n",
              "                      [-8.4858e-02,  3.3793e-02,  1.5533e-01,  1.9089e-01, -6.2007e-02,\n",
              "                       -2.2256e-01,  2.4470e-01, -1.6226e-01,  1.2315e-01, -1.3258e-02,\n",
              "                        6.6877e-02,  8.7803e-02,  1.9119e-01,  9.9941e-02],\n",
              "                      [ 2.4025e-02, -1.7564e-01, -7.3002e-02,  2.9759e-01,  1.8441e-01,\n",
              "                        9.3774e-02, -4.7761e-02,  1.4893e-01,  2.4481e-02, -2.2465e-01,\n",
              "                        7.9136e-02, -2.1980e-01, -1.8507e-01, -1.2521e-01],\n",
              "                      [ 5.3994e-02,  2.4716e-01,  1.5720e-01, -3.1985e-01,  3.9301e-02,\n",
              "                       -7.3506e-02, -1.4903e-01, -1.2709e-01, -8.4198e-02, -1.4468e-01,\n",
              "                       -3.4996e-02,  9.4156e-02, -3.9506e-02,  1.9770e-01],\n",
              "                      [-2.0511e-01,  4.4236e-02,  4.3889e-02, -3.2388e-02, -2.0953e-01,\n",
              "                       -8.9592e-02, -9.4738e-02, -8.0775e-02, -2.4461e-01, -1.7495e-02,\n",
              "                       -2.1808e-01,  1.7696e-01,  1.1769e-01,  2.7048e-01],\n",
              "                      [-7.0795e-02,  1.1275e-01,  1.9849e-01,  1.5749e-01, -5.6443e-02,\n",
              "                       -1.7885e-01,  2.6580e-01,  1.6319e-01,  2.0179e-01, -1.1990e-01,\n",
              "                        5.0582e-02, -7.9438e-02,  2.1772e-01, -2.4185e-01],\n",
              "                      [-1.0238e-01, -1.2386e-01, -5.4771e-02,  7.2190e-02,  2.1247e-01,\n",
              "                       -7.5740e-02,  1.1654e-01,  1.1636e-01, -1.0526e-01,  2.1002e-01,\n",
              "                       -9.2188e-02,  1.6720e-01, -1.5439e-01, -2.2589e-01],\n",
              "                      [-1.4406e-01,  3.8038e-02, -1.7058e-01, -1.4278e-01,  1.9941e-01,\n",
              "                        1.9163e-01, -6.4247e-02,  1.4632e-01, -1.8376e-01, -7.7356e-02,\n",
              "                       -1.9296e-01, -1.9662e-01,  4.4496e-02, -6.6459e-03],\n",
              "                      [-2.4181e-01, -6.6623e-02, -1.5749e-01, -1.8306e-01, -5.7402e-02,\n",
              "                       -2.3134e-01, -2.0467e-01, -1.6340e-01,  2.1887e-01, -5.3716e-02,\n",
              "                       -2.6805e-02,  2.1844e-01, -1.3748e-03,  1.2068e-01],\n",
              "                      [ 9.9682e-02,  2.5710e-01, -1.2119e-01, -2.3079e-01, -3.3157e-01,\n",
              "                        1.4210e-01,  8.6852e-02, -3.4998e-02, -8.4927e-02,  1.8023e-01,\n",
              "                        1.7106e-01, -8.3438e-02, -3.3441e-02,  1.1356e-01],\n",
              "                      [-1.0038e-01,  2.0735e-01, -8.1741e-02, -1.5744e-01,  3.9912e-02,\n",
              "                        2.3010e-01, -9.0822e-02,  2.4850e-03,  2.1460e-01,  1.2986e-01,\n",
              "                        2.4904e-01,  2.1189e-01, -9.6146e-02,  2.1333e-01],\n",
              "                      [-2.2169e-01,  2.5758e-01,  2.5939e-01,  1.3477e-01, -1.7808e-01,\n",
              "                       -1.4214e-01, -4.8432e-02, -1.2193e-01, -1.0882e-01, -1.4598e-01,\n",
              "                       -1.1050e-01,  1.9913e-01,  9.2816e-02, -1.9525e-01],\n",
              "                      [-1.5827e-01,  2.4701e-01, -1.3547e-01, -2.0920e-01, -3.0452e-02,\n",
              "                        2.1280e-01, -8.2875e-02, -8.1321e-02, -2.4011e-01,  7.9235e-02,\n",
              "                       -1.3409e-01, -2.2820e-01,  1.2566e-02,  8.8168e-02],\n",
              "                      [ 2.7380e-01, -1.8475e-01,  4.3451e-03, -2.6643e-02,  6.1147e-02,\n",
              "                        8.0864e-02,  2.9367e-01, -3.7988e-03,  6.5031e-02, -1.7585e-01,\n",
              "                       -6.6624e-02,  8.6356e-02,  1.1154e-01, -1.3820e-01],\n",
              "                      [ 2.6642e-01,  2.4370e-01,  1.7195e-01, -1.5659e-01,  2.1774e-01,\n",
              "                        1.5076e-01, -2.2001e-01, -8.2266e-02,  1.6684e-01,  3.4458e-02,\n",
              "                        2.2485e-01,  6.9354e-02,  1.3261e-01, -1.6189e-02],\n",
              "                      [-2.6896e-01, -2.1463e-02,  8.0599e-02, -5.7766e-02, -1.0097e-01,\n",
              "                        1.4055e-02, -2.2881e-02, -1.6522e-01,  1.9452e-01,  2.4298e-02,\n",
              "                       -3.2436e-02, -9.2017e-02,  4.3215e-02, -1.1776e-01],\n",
              "                      [-2.4004e-01, -2.4171e-01,  3.8431e-02,  1.6486e-01, -1.6559e-01,\n",
              "                       -2.5703e-01, -9.1561e-02, -2.7794e-02,  1.8955e-01, -1.3827e-01,\n",
              "                       -6.8325e-02, -1.8359e-01, -2.2329e-01,  7.2757e-02],\n",
              "                      [ 1.8972e-01,  1.2383e-01,  1.7147e-01, -2.0325e-01, -2.0188e-01,\n",
              "                        2.9763e-03,  6.5587e-02,  9.7804e-02, -1.8639e-01, -2.1657e-01,\n",
              "                       -2.5280e-01,  4.1869e-02,  2.2666e-01, -1.1108e-01],\n",
              "                      [-1.0882e-01,  6.4807e-02,  1.7820e-02,  1.7068e-01, -1.9518e-01,\n",
              "                       -2.0477e-01,  1.8215e-01,  6.6111e-02, -4.2070e-02,  4.8514e-02,\n",
              "                       -2.4125e-01, -2.1125e-01, -2.5656e-01, -1.3603e-01],\n",
              "                      [ 1.6582e-01, -1.1873e-01, -8.6598e-02, -2.3973e-02,  3.5725e-04,\n",
              "                       -1.6610e-01,  1.3243e-01,  1.2721e-01, -1.3905e-01,  2.5530e-01,\n",
              "                       -1.3089e-01, -1.7792e-01, -1.4131e-01, -9.9594e-03],\n",
              "                      [ 1.8886e-01, -2.0230e-01,  2.2494e-01,  2.1063e-01,  9.5028e-02,\n",
              "                        1.7364e-01, -2.4336e-01,  2.0394e-01, -3.8338e-02, -6.3576e-02,\n",
              "                        1.8130e-01,  1.9229e-01,  2.0395e-01,  4.9992e-02],\n",
              "                      [ 4.9678e-02,  5.0730e-02,  7.9305e-02, -1.7849e-01,  7.3340e-02,\n",
              "                       -4.8485e-02,  1.5475e-01,  2.2778e-01, -8.0952e-02,  1.6478e-01,\n",
              "                       -1.4006e-02, -1.6498e-01,  2.1531e-01, -1.6609e-01],\n",
              "                      [ 3.5802e-02,  3.4774e-02, -1.2189e-01, -2.8527e-02,  2.1777e-01,\n",
              "                       -2.2632e-01, -1.8145e-01, -1.6786e-01,  8.2560e-03,  1.8475e-01,\n",
              "                       -1.5526e-01,  6.5406e-02,  1.2069e-01,  2.8421e-01],\n",
              "                      [-2.5429e-01, -2.2265e-01, -5.8362e-03,  2.1779e-01,  1.0949e-01,\n",
              "                       -1.2972e-01,  1.5278e-01,  2.2596e-01,  2.2785e-01,  2.3349e-01,\n",
              "                       -1.2357e-01,  2.4070e-01,  1.3839e-01,  2.6502e-01],\n",
              "                      [ 2.2827e-01,  1.8338e-01, -7.5005e-02,  1.3382e-01,  1.3353e-02,\n",
              "                       -4.6916e-02, -6.9693e-02,  2.3622e-01,  2.2483e-01, -1.6584e-01,\n",
              "                       -1.7444e-01,  6.4811e-02,  1.8206e-01,  2.0858e-02],\n",
              "                      [ 1.4175e-01,  1.5664e-01,  2.3136e-01, -1.3486e-01,  2.1659e-01,\n",
              "                       -1.9387e-01, -1.8826e-01, -2.3859e-01, -3.9004e-02,  1.1667e-03,\n",
              "                        8.5692e-02,  2.7465e-01, -9.9658e-02,  2.0344e-01],\n",
              "                      [ 1.2160e-01,  1.0901e-01,  1.3318e-01, -9.6556e-02,  2.0924e-01,\n",
              "                       -1.8902e-01, -2.3468e-01,  2.1464e-02, -2.0778e-01,  2.0704e-01,\n",
              "                       -4.4854e-02,  2.4179e-01,  5.4550e-02, -2.2639e-01],\n",
              "                      [ 2.0980e-01,  8.6652e-03, -6.5545e-02,  2.3714e-01, -9.9817e-02,\n",
              "                       -1.6788e-01, -4.3076e-03,  9.9583e-02, -4.7734e-02, -1.6256e-01,\n",
              "                        1.4813e-01,  2.0732e-01,  1.4464e-01,  2.2537e-01]], device='cuda:0')),\n",
              "             ('L1.bias',\n",
              "              tensor([ 0.2028, -0.2251,  0.0254, -0.2655, -0.1691, -0.1046, -0.1617,  0.1096,\n",
              "                      -0.0708, -0.0549,  0.1679, -0.2643, -0.2437,  0.1305,  0.0340,  0.1428,\n",
              "                      -0.1786,  0.0191,  0.1614, -0.1901, -0.1049, -0.0721, -0.0193, -0.0381,\n",
              "                      -0.1972, -0.0354, -0.2035, -0.2905, -0.0981,  0.0691, -0.1080,  0.1027,\n",
              "                       0.1229,  0.0543, -0.2150,  0.1508,  0.0334,  0.0753, -0.0335,  0.0393,\n",
              "                       0.1247,  0.1420, -0.1981,  0.1820, -0.0995, -0.2405,  0.0394, -0.1994,\n",
              "                      -0.0147,  0.2276,  0.2324, -0.2081, -0.1690,  0.1113, -0.1222, -0.0409,\n",
              "                      -0.0334, -0.1552,  0.1202,  0.2003,  0.0964, -0.2067, -0.0385,  0.0265],\n",
              "                     device='cuda:0')),\n",
              "             ('L2.weight',\n",
              "              tensor([[ 0.0485,  0.0037, -0.0875,  0.0029,  0.1096, -0.0153,  0.0102, -0.0970,\n",
              "                       -0.0017,  0.0878, -0.0071,  0.0174, -0.0104,  0.0479, -0.0202, -0.0238,\n",
              "                        0.0030,  0.0283,  0.0242,  0.0654, -0.0179,  0.0315, -0.0818, -0.0094,\n",
              "                       -0.0829,  0.0799,  0.0183,  0.3060, -0.0108,  0.0225,  0.0493,  0.0829,\n",
              "                        0.0780, -0.0245, -0.0492,  0.0053, -0.1166,  0.0206,  0.0250,  0.1097,\n",
              "                       -0.0080, -0.0648,  0.0143,  0.0195,  0.0053,  0.0722,  0.0281, -0.0248,\n",
              "                       -0.0260,  0.0242,  0.0372,  0.0585,  0.0890, -0.0236, -0.0046, -0.0067,\n",
              "                       -0.0055,  0.0296, -0.0456, -0.0341,  0.0630, -0.0552, -0.0178, -0.0494]],\n",
              "                     device='cuda:0')),\n",
              "             ('L2.bias', tensor([-0.0169], device='cuda:0')),\n",
              "             ('bn1.weight',\n",
              "              tensor([0.9851, 1.0032, 0.9723, 0.9768, 1.0002, 0.9710, 0.9894, 0.9933, 1.0070,\n",
              "                      0.9793, 0.9178, 0.9470, 0.9201, 1.0178, 1.0150, 0.9990, 0.9734, 0.9891,\n",
              "                      0.9751, 0.9941, 1.0124, 0.9569, 0.9689, 1.0155, 0.9876, 0.9726, 0.9537,\n",
              "                      1.3452, 0.9159, 0.9897, 0.9474, 0.9624, 0.9980, 0.9391, 0.9702, 0.9606,\n",
              "                      0.9956, 0.9786, 0.9402, 0.9958, 0.9677, 0.9787, 0.9159, 1.0086, 0.9781,\n",
              "                      0.9897, 0.9821, 0.9739, 0.9210, 0.9742, 1.0101, 0.9793, 0.9946, 0.9749,\n",
              "                      0.9838, 0.9916, 0.9992, 1.0270, 0.9597, 1.0303, 0.9955, 0.9389, 0.9583,\n",
              "                      0.9933], device='cuda:0')),\n",
              "             ('bn1.bias',\n",
              "              tensor([ 0.0038, -0.0002, -0.0053,  0.0011,  0.0058, -0.0019, -0.0006, -0.0047,\n",
              "                      -0.0007,  0.0051, -0.0038,  0.0028, -0.0032,  0.0023, -0.0022, -0.0019,\n",
              "                       0.0017,  0.0033,  0.0027,  0.0037, -0.0004,  0.0027, -0.0052, -0.0007,\n",
              "                      -0.0047,  0.0055,  0.0032,  0.0068, -0.0036,  0.0012,  0.0034,  0.0058,\n",
              "                       0.0047, -0.0031, -0.0037,  0.0015, -0.0057,  0.0015,  0.0033,  0.0062,\n",
              "                       0.0010, -0.0043,  0.0038,  0.0005,  0.0013,  0.0047,  0.0026,  0.0001,\n",
              "                      -0.0037,  0.0026,  0.0034,  0.0038,  0.0049, -0.0012,  0.0001,  0.0005,\n",
              "                      -0.0009,  0.0013, -0.0039, -0.0033,  0.0042, -0.0045, -0.0023, -0.0033],\n",
              "                     device='cuda:0')),\n",
              "             ('bn1.running_mean',\n",
              "              tensor([3.6483e-01, 2.7763e-03, 1.3236e-01, 1.4925e-03, 6.4076e-02, 2.3950e-03,\n",
              "                      1.6297e-03, 9.2933e-01, 2.9661e-01, 2.4737e-01, 3.8827e-02, 2.7654e-04,\n",
              "                      7.5248e-02, 5.8220e-02, 3.8127e-01, 2.6109e-01, 4.0161e-04, 3.4589e-01,\n",
              "                      3.4459e-01, 3.3348e-01, 3.3340e-04, 1.2014e-01, 2.1104e-01, 2.8997e-02,\n",
              "                      3.5104e-07, 1.3786e-01, 1.7557e-04, 9.2376e-03, 2.3031e-03, 3.0708e-01,\n",
              "                      9.6765e-02, 2.1909e-01, 3.8652e-01, 5.3568e-02, 1.7663e-21, 9.3150e-03,\n",
              "                      4.0958e-01, 3.4663e-01, 1.9984e-02, 1.7533e-01, 9.4821e-02, 4.1198e-01,\n",
              "                      4.1535e-03, 5.8128e-02, 2.7273e-03, 6.1284e-02, 4.6224e-01, 2.2011e-02,\n",
              "                      1.5405e-02, 4.1905e-01, 8.3747e-01, 2.8663e-16, 6.2358e-43, 2.3609e-01,\n",
              "                      9.7277e-04, 1.0391e-02, 5.4190e-01, 1.0326e-01, 1.5137e-01, 4.8128e-01,\n",
              "                      4.4326e-01, 1.6521e-01, 1.2980e-01, 4.5000e-01], device='cuda:0')),\n",
              "             ('bn1.running_var',\n",
              "              tensor([3.7728e-02, 3.4950e-04, 2.5760e-02, 1.3530e-04, 8.9667e-03, 3.1563e-04,\n",
              "                      1.5503e-04, 7.7377e-02, 4.9041e-02, 4.0182e-02, 7.5623e-03, 2.0571e-05,\n",
              "                      1.6334e-02, 1.0612e-02, 3.6488e-02, 3.1684e-02, 2.6928e-05, 6.1505e-02,\n",
              "                      7.1317e-02, 4.3632e-02, 4.6816e-05, 2.6264e-02, 3.6737e-02, 4.4061e-03,\n",
              "                      1.5997e-08, 2.7031e-02, 1.1245e-05, 9.8294e-04, 2.7214e-04, 6.4065e-02,\n",
              "                      1.8130e-02, 3.6254e-02, 5.6684e-02, 9.0322e-03, 1.7507e-23, 1.3265e-03,\n",
              "                      4.5644e-02, 4.6523e-02, 3.7937e-03, 2.7646e-02, 1.9276e-02, 5.7815e-02,\n",
              "                      6.1220e-04, 1.1310e-02, 3.0602e-04, 1.1639e-02, 5.6112e-02, 4.0463e-03,\n",
              "                      2.4068e-03, 4.6577e-02, 7.4049e-02, 3.8427e-18, 5.6052e-45, 3.4192e-02,\n",
              "                      1.1670e-04, 1.5541e-03, 8.3737e-02, 1.8966e-02, 3.0760e-02, 7.2384e-02,\n",
              "                      5.0588e-02, 3.8018e-02, 2.7508e-02, 5.0845e-02], device='cuda:0')),\n",
              "             ('bn1.num_batches_tracked', tensor(6040, device='cuda:0')),\n",
              "             ('bn2.weight', tensor([0.4624], device='cuda:0')),\n",
              "             ('bn2.bias', tensor([0.0631], device='cuda:0')),\n",
              "             ('bn2.running_mean', tensor([-0.0048], device='cuda:0')),\n",
              "             ('bn2.running_var', tensor([0.3028], device='cuda:0')),\n",
              "             ('bn2.num_batches_tracked', tensor(6040, device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}