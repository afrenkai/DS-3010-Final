{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQi79Yxbl6bfnuxovDBaLb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEvTRtNnDY2Q",
        "outputId": "3e23d5b5-6bb0-44b6-d3bb-9ede953ea50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS-3010-Final'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 77 (delta 26), reused 61 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 16.15 MiB | 13.02 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/afrenkai/DS-3010-Final.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DS-3010-Final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiUGv3JMDiIb",
        "outputId": "aa1cf287-9032-4caa-9c28-f801d0da57e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DS-3010-Final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Exc780BDznq",
        "outputId": "adeda21a-41ff-4783-cce6-0cbc9de865d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv.py  data.ipynb  main.py\t\tREADME.md\t  setup.bat\n",
            "Data   LICENSE\t   Preprocessing.ipynb\trequirements.txt  sgemm_product.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "KjqLGK9uDuvW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('Data/SGEMM_train.csv')\n",
        "val_df = pd.read_csv('Data/SGEMM_val.csv')"
      ],
      "metadata": {
        "id": "jSFtZgO5EIYi"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "yFsL0jLPEah0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x, xmin, xmax, a, b):\n",
        "  '''\n",
        "  Restricts x values to range of [xmin, xmax]\n",
        "  '''\n",
        "  numerator = x - xmin\n",
        "  denominator = xmax - xmin\n",
        "  return (numerator / denominator) * (b - a) + a"
      ],
      "metadata": {
        "id": "VeZMpJ4fWVnS"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_combine = ['Run1 (ms)', 'Run2 (ms)', 'Run3 (ms)', 'Run4 (ms)']"
      ],
      "metadata": {
        "id": "Zg8_iVh1EoPf"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame):\n",
        "  df['DELTA_RUNTIME'] = df.apply(\n",
        "      lambda row: np.mean([row['Run1 (ms)'], row['Run2 (ms)'], row['Run3 (ms)'], row['Run4 (ms)']]),\n",
        "      axis=1\n",
        "  )\n",
        "  for col in df.columns:\n",
        "    if col in cols_to_combine:\n",
        "      df = df.drop(col, axis = 1)\n",
        "  min = 0\n",
        "  max = 1\n",
        "\n",
        "\n",
        "  df = df.apply(\n",
        "      lambda row: (norm(row, row.min(), row.max(), min, max))\n",
        "  )\n",
        "  x = df.iloc[:, :14]\n",
        "  y = df.iloc[:, -1:]\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "t7Ldc6DaEWb5"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXYcVqELKyXo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lin Reg"
      ],
      "metadata": {
        "id": "NFV1wQRbLjXP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "499JbLKILks_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poly Reg"
      ],
      "metadata": {
        "id": "2Do_3rddLlRf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bWXyH5z-Lmnt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Net"
      ],
      "metadata": {
        "id": "GKjUYgsALmtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPUNN(nn.Module):\n",
        "  def __init__(self, in_feat, out_feat):\n",
        "    super(GPUNN, self).__init__()\n",
        "    self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "    self.L1 = nn.Linear(in_feat, 64, device=self.device)\n",
        "    self.L2 = nn.Linear(64, out_feat, device = self.device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(64, device = self.device)\n",
        "    self.bn2 = nn.BatchNorm1d(out_feat, device = self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.relu(self.L1(x)))\n",
        "    x = self.bn2(self.L2(x))\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "TJtfhd5sLoz2"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, train_dl: DataLoader, batch_size, device, n_epochs, optimizer, criterion):\n",
        "  model.train()\n",
        "  for batch, (data, target) in enumerate(train_dl):\n",
        "\n",
        "    data, target = data.to(device).float(), target.to(device).float()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                n_epochs, batch * len(data), len(train_dl.dataset),\n",
        "                100. * batch / len(train_dl), loss.item()))\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jrBA-CHTOLEl"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device).float(), target.to(device).float()\n",
        "            output = model(data)\n",
        "            test_loss = criterion(output, target)\n",
        "    print(test_loss / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-NN3jSkBVjKt"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dls(x: pd.DataFrame, y:pd.DataFrame):\n",
        "  x = x.loc[:, :].values\n",
        "  y = y.loc[:, :].values\n",
        "  x_ten = torch.tensor(x)\n",
        "  y_ten = torch.tensor(y)\n",
        "  ds = TensorDataset(x_ten, y_ten)\n",
        "  dl = DataLoader(ds, batch_size = 32)\n",
        "  return ds, dl"
      ],
      "metadata": {
        "id": "8ZQiw6qdP-5v"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, y_tr = preprocess(train_df)\n",
        "model = GPUNN(len(x_tr.columns), len(y_tr.columns))\n",
        "print(model)\n",
        "_, train_dl = create_dls(x_tr, y_tr)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
        "train(model, train_dl, 32, model.device, 10, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8nqyTzNkF6",
        "outputId": "465a7b15-30fa-4183-f865-5479c7206b68"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUNN(\n",
            "  (L1): Linear(in_features=14, out_features=64, bias=True)\n",
            "  (L2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "Train Epoch: 10 [0/193280 (0%)]\tLoss: 1.009503\n",
            "Train Epoch: 10 [3200/193280 (2%)]\tLoss: 0.985756\n",
            "Train Epoch: 10 [6400/193280 (3%)]\tLoss: 0.933287\n",
            "Train Epoch: 10 [9600/193280 (5%)]\tLoss: 0.924185\n",
            "Train Epoch: 10 [12800/193280 (7%)]\tLoss: 0.841165\n",
            "Train Epoch: 10 [16000/193280 (8%)]\tLoss: 0.755664\n",
            "Train Epoch: 10 [19200/193280 (10%)]\tLoss: 0.712093\n",
            "Train Epoch: 10 [22400/193280 (12%)]\tLoss: 0.784422\n",
            "Train Epoch: 10 [25600/193280 (13%)]\tLoss: 0.777486\n",
            "Train Epoch: 10 [28800/193280 (15%)]\tLoss: 0.713609\n",
            "Train Epoch: 10 [32000/193280 (17%)]\tLoss: 0.743223\n",
            "Train Epoch: 10 [35200/193280 (18%)]\tLoss: 0.673932\n",
            "Train Epoch: 10 [38400/193280 (20%)]\tLoss: 0.695695\n",
            "Train Epoch: 10 [41600/193280 (22%)]\tLoss: 0.660347\n",
            "Train Epoch: 10 [44800/193280 (23%)]\tLoss: 0.660578\n",
            "Train Epoch: 10 [48000/193280 (25%)]\tLoss: 0.581792\n",
            "Train Epoch: 10 [51200/193280 (26%)]\tLoss: 0.667443\n",
            "Train Epoch: 10 [54400/193280 (28%)]\tLoss: 0.613351\n",
            "Train Epoch: 10 [57600/193280 (30%)]\tLoss: 0.507368\n",
            "Train Epoch: 10 [60800/193280 (31%)]\tLoss: 0.584959\n",
            "Train Epoch: 10 [64000/193280 (33%)]\tLoss: 0.583112\n",
            "Train Epoch: 10 [67200/193280 (35%)]\tLoss: 0.443642\n",
            "Train Epoch: 10 [70400/193280 (36%)]\tLoss: 0.590009\n",
            "Train Epoch: 10 [73600/193280 (38%)]\tLoss: 0.431525\n",
            "Train Epoch: 10 [76800/193280 (40%)]\tLoss: 0.509439\n",
            "Train Epoch: 10 [80000/193280 (41%)]\tLoss: 0.455756\n",
            "Train Epoch: 10 [83200/193280 (43%)]\tLoss: 0.504533\n",
            "Train Epoch: 10 [86400/193280 (45%)]\tLoss: 0.410830\n",
            "Train Epoch: 10 [89600/193280 (46%)]\tLoss: 0.351077\n",
            "Train Epoch: 10 [92800/193280 (48%)]\tLoss: 0.345740\n",
            "Train Epoch: 10 [96000/193280 (50%)]\tLoss: 0.370839\n",
            "Train Epoch: 10 [99200/193280 (51%)]\tLoss: 0.434940\n",
            "Train Epoch: 10 [102400/193280 (53%)]\tLoss: 0.416070\n",
            "Train Epoch: 10 [105600/193280 (55%)]\tLoss: 0.373787\n",
            "Train Epoch: 10 [108800/193280 (56%)]\tLoss: 0.326888\n",
            "Train Epoch: 10 [112000/193280 (58%)]\tLoss: 0.407770\n",
            "Train Epoch: 10 [115200/193280 (60%)]\tLoss: 0.333966\n",
            "Train Epoch: 10 [118400/193280 (61%)]\tLoss: 0.326523\n",
            "Train Epoch: 10 [121600/193280 (63%)]\tLoss: 0.337198\n",
            "Train Epoch: 10 [124800/193280 (65%)]\tLoss: 0.378582\n",
            "Train Epoch: 10 [128000/193280 (66%)]\tLoss: 0.311575\n",
            "Train Epoch: 10 [131200/193280 (68%)]\tLoss: 0.299899\n",
            "Train Epoch: 10 [134400/193280 (70%)]\tLoss: 0.311575\n",
            "Train Epoch: 10 [137600/193280 (71%)]\tLoss: 0.216349\n",
            "Train Epoch: 10 [140800/193280 (73%)]\tLoss: 0.304443\n",
            "Train Epoch: 10 [144000/193280 (75%)]\tLoss: 0.298468\n",
            "Train Epoch: 10 [147200/193280 (76%)]\tLoss: 0.290149\n",
            "Train Epoch: 10 [150400/193280 (78%)]\tLoss: 0.194438\n",
            "Train Epoch: 10 [153600/193280 (79%)]\tLoss: 0.185004\n",
            "Train Epoch: 10 [156800/193280 (81%)]\tLoss: 0.175159\n",
            "Train Epoch: 10 [160000/193280 (83%)]\tLoss: 0.181780\n",
            "Train Epoch: 10 [163200/193280 (84%)]\tLoss: 0.244427\n",
            "Train Epoch: 10 [166400/193280 (86%)]\tLoss: 0.208525\n",
            "Train Epoch: 10 [169600/193280 (88%)]\tLoss: 0.192764\n",
            "Train Epoch: 10 [172800/193280 (89%)]\tLoss: 0.212275\n",
            "Train Epoch: 10 [176000/193280 (91%)]\tLoss: 0.212166\n",
            "Train Epoch: 10 [179200/193280 (93%)]\tLoss: 0.107929\n",
            "Train Epoch: 10 [182400/193280 (94%)]\tLoss: 0.160260\n",
            "Train Epoch: 10 [185600/193280 (96%)]\tLoss: 0.171472\n",
            "Train Epoch: 10 [188800/193280 (98%)]\tLoss: 0.172055\n",
            "Train Epoch: 10 [192000/193280 (99%)]\tLoss: 0.150252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, y_val = preprocess(val_df)\n",
        "_, val_dl = create_dls(x_val, y_val)\n",
        "criterion = nn.MSELoss()\n",
        "test(model, model.device, val_dl, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZcQqEQV7BA",
        "outputId": "a44491e3-3ff0-4080-adee-6897d7683065"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.5191e-06, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOYlwVqjXoMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}