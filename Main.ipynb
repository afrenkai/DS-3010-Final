{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEvTRtNnDY2Q",
        "outputId": "170650cf-93bd-4a1d-b8e3-b8081fbdcb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS-3010-Final'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 131 (delta 55), reused 81 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (131/131), 18.28 MiB | 7.87 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/afrenkai/DS-3010-Final.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DS-3010-Final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiUGv3JMDiIb",
        "outputId": "4106f926-61d9-481f-9048-cb329b320cb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DS-3010-Final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Exc780BDznq",
        "outputId": "cc3d4d92-4fe2-4e8b-f490-8f338278d895"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv.py  LICENSE\t   new_3010_proj_work_ben.ipynb  requirements.txt\n",
            "Data   Main.ipynb  README.md\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.13.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from lightgbm import LGBMRegressor\n",
        "from torcheval.metrics import R2Score"
      ],
      "metadata": {
        "id": "KjqLGK9uDuvW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('Data/SGEMM_train.csv')\n",
        "val_df = pd.read_csv('Data/SGEMM_val.csv')\n",
        "\n",
        "#TODO: read test data (already in data dir), see what's going on in lightgbm, get r2 for the neural net"
      ],
      "metadata": {
        "id": "jSFtZgO5EIYi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing"
      ],
      "metadata": {
        "id": "yFsL0jLPEah0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x, xmin, xmax, a, b):\n",
        "  '''\n",
        "  Restricts x values to range of [xmin, xmax]\n",
        "  '''\n",
        "  numerator = x - xmin\n",
        "  denominator = xmax - xmin\n",
        "  return (numerator / denominator) * (b - a) + a"
      ],
      "metadata": {
        "id": "VeZMpJ4fWVnS"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_combine = ['Run1 (ms)', 'Run2 (ms)', 'Run3 (ms)', 'Run4 (ms)']"
      ],
      "metadata": {
        "id": "Zg8_iVh1EoPf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame):\n",
        "  df['DELTA_RUNTIME'] = df.apply(\n",
        "      lambda row: np.mean([row['Run1 (ms)'], row['Run2 (ms)'], row['Run3 (ms)'], row['Run4 (ms)']]),\n",
        "      axis=1\n",
        "  )\n",
        "  for col in df.columns:\n",
        "    if col in cols_to_combine:\n",
        "      df = df.drop(col, axis = 1) #removes redundant cols\n",
        "\n",
        "\n",
        "  min = 0\n",
        "  max = 1\n",
        "\n",
        "  df = df.apply(\n",
        "      lambda row: (norm(row, row.min(), row.max(), min, max))\n",
        "  )\n",
        "  x = df.iloc[:, :14] # features\n",
        "  y = df.iloc[:, -1:] # target\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "t7Ldc6DaEWb5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "DsGLn9WEE1Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_tr, y_tr = preprocess(train_df)\n",
        "\n",
        "train_data = lgb.Dataset(x_tr, label=y_tr)\n",
        "x_val, y_val = preprocess(val_df)\n",
        "# Create a LightGBM dataset for testing with features X_val and labels Y_val,\n",
        "# and specify the reference dataset as train_data for consistent evaluation\n",
        "val_data = lgb.Dataset(x_val, label=y_val, reference=train_data)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "}\n",
        "\n",
        "num_round = 100\n",
        "bst = lgb.train(params, train_data, num_round, valid_sets=[\n",
        "                val_data])\n",
        "\n",
        "\n",
        "# Create an instance of the LightGBM Regressor with the RMSE metric.\n",
        "model = LGBMRegressor(metric='mse')\n",
        "\n",
        "# Train the model using the training data.\n",
        "model.fit(x_tr, y_tr)\n",
        "\n",
        "y_train = model.predict(x_tr)\n",
        "y_v = model.predict(x_val)\n",
        "print(\"Training MSE:\", mse(y_tr, y_train))\n",
        "print(\"Validation MSE:\", mse(y_val, y_v))\n",
        "\n",
        "print('train r2:', r2_score(y_tr, y_train))\n",
        "print('val r2:', r2_score(y_val, y_v))"
      ],
      "metadata": {
        "id": "bWXyH5z-Lmnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c8c396-b4a9-4ab9-cd53-eef5bd4b5dac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 40\n",
            "[LightGBM] [Info] Number of data points in the train set: 193280, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.061354\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030284 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 40\n",
            "[LightGBM] [Info] Number of data points in the train set: 193280, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 0.061354\n",
            "Training MSE: 0.00012048252219381041\n",
            "Validation MSE: 0.0001191615359407208\n",
            "train r2: 0.9901529624802171\n",
            "val r2: 0.9903041142135522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Net"
      ],
      "metadata": {
        "id": "GKjUYgsALmtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPUNN(nn.Module):\n",
        "  def __init__(self, in_feat, out_feat):\n",
        "    super(GPUNN, self).__init__()\n",
        "    self.device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "    self.L1 = nn.Linear(in_feat, 64, device=self.device)\n",
        "    self.L2 = nn.Linear(64, out_feat, device = self.device)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(64, device = self.device)\n",
        "    self.bn2 = nn.BatchNorm1d(out_feat, device = self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.relu(self.L1(x)))\n",
        "    x = self.bn2(self.L2(x))\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "TJtfhd5sLoz2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training output example was basen on an example from pytorch on using CNNs for ImageNet. https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "# lines 45-48 in original code, lines roughly 13-16 in ours\n",
        "def train(model: nn.Module, train_dl: DataLoader, batch_size, device, n_epochs, optimizer, criterion):\n",
        "    model.train()\n",
        "    for epoch in trange(n_epochs):\n",
        "        for batch, (data, target) in enumerate(train_dl):\n",
        "            data, target = data.to(device).float(), target.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch % 1000 == 0:\n",
        "                print('\\nTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch + 1, batch * len(data), len(train_dl.dataset),\n",
        "                    100. * batch / len(train_dl), loss.item()))\n",
        "\n",
        "    torch.save(model.state_dict(), 'nn.pth')\n",
        "    print('model saved to nn.pth')\n"
      ],
      "metadata": {
        "id": "jrBA-CHTOLEl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r2 score stuff taken from https://pytorch.org/torcheval/main/generated/torcheval.metrics.R2Score.html\n",
        "#I think meaning loss over batches is fair, since that's a relatively good indicator of performance.\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    losses = []\n",
        "    metric = R2Score()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device).float(), target.to(device).float()\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss = criterion(output, target)\n",
        "            # print('loss bien')\n",
        "            # print(f'Target Tensor: {target.detach().cpu().numpy()}\\n, Output Tensor:{output.detach().cpu().numpy()}\\n')\n",
        "\n",
        "            metric.update(output, target)\n",
        "            # print(f' r2 rn: {metric.compute()}')\n",
        "\n",
        "            # print('r2 bien')\n",
        "            losses.append(test_loss)\n",
        "\n",
        "\n",
        "    # print(test_loss / len(test_loader.dataset))\n",
        "    # print(np.mean(r2s))\n",
        "    r2 = metric.compute()\n",
        "    r2 = float(r2.detach().cpu().numpy())\n",
        "    # print(type(r2))\n",
        "    # print(round(r2, 4))\n",
        "    return (np.mean([ten.detach().cpu().numpy() for ten in losses]), round(r2, 4) )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-NN3jSkBVjKt"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dls(x: pd.DataFrame, y:pd.DataFrame, split: str = 'train'):\n",
        "  x = x.loc[:, :].values #conv to np array\n",
        "  y = y.loc[:, :].values\n",
        "  x_ten = torch.tensor(x) # conv to tensor\n",
        "  y_ten = torch.tensor(y)\n",
        "  ds = TensorDataset(x_ten, y_ten)\n",
        "  if split == 'train':\n",
        "    dl = DataLoader(ds, batch_size = 32, shuffle = True) #safe to shuffle since its train\n",
        "  else:\n",
        "    dl = DataLoader(ds, batch_size = 32, shuffle = False) #assuming test/val, can't shuffle\n",
        "  return ds, dl"
      ],
      "metadata": {
        "id": "8ZQiw6qdP-5v"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, y_tr = preprocess(train_df)\n",
        "model = GPUNN(len(x_tr.columns), len(y_tr.columns))\n",
        "print(model)\n",
        "_, train_dl = create_dls(x_tr, y_tr)\n",
        "criterion = nn.MSELoss() # MSE, like we've been using everywhere else\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4) # pretty standard, no need for k-fold since the method works pretty well without tuning\n",
        "train(model, train_dl, 32, model.device, 10, optimizer, criterion) # 10 epochs to get a baseline."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8nqyTzNkF6",
        "outputId": "7dd6be81-1021-4934-93ee-90ab59320428"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUNN(\n",
            "  (L1): Linear(in_features=14, out_features=64, bias=True)\n",
            "  (L2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 1 [0/193280 (0%)]\tLoss: 1.020140\n",
            "\n",
            "Train Epoch: 1 [32000/193280 (17%)]\tLoss: 0.653175\n",
            "\n",
            "Train Epoch: 1 [64000/193280 (33%)]\tLoss: 0.587248\n",
            "\n",
            "Train Epoch: 1 [96000/193280 (50%)]\tLoss: 0.366149\n",
            "\n",
            "Train Epoch: 1 [128000/193280 (66%)]\tLoss: 0.320002\n",
            "\n",
            "Train Epoch: 1 [160000/193280 (83%)]\tLoss: 0.241567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:11<01:44, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 1 [192000/193280 (99%)]\tLoss: 0.087700\n",
            "\n",
            "Train Epoch: 2 [0/193280 (0%)]\tLoss: 0.171225\n",
            "\n",
            "Train Epoch: 2 [32000/193280 (17%)]\tLoss: 0.042149\n",
            "\n",
            "Train Epoch: 2 [64000/193280 (33%)]\tLoss: 0.049729\n",
            "\n",
            "Train Epoch: 2 [96000/193280 (50%)]\tLoss: 0.018328\n",
            "\n",
            "Train Epoch: 2 [128000/193280 (66%)]\tLoss: 0.019041\n",
            "\n",
            "Train Epoch: 2 [160000/193280 (83%)]\tLoss: 0.008792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:23<01:32, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 2 [192000/193280 (99%)]\tLoss: 0.002969\n",
            "\n",
            "Train Epoch: 3 [0/193280 (0%)]\tLoss: 0.003069\n",
            "\n",
            "Train Epoch: 3 [32000/193280 (17%)]\tLoss: 0.003417\n",
            "\n",
            "Train Epoch: 3 [64000/193280 (33%)]\tLoss: 0.001408\n",
            "\n",
            "Train Epoch: 3 [96000/193280 (50%)]\tLoss: 0.003319\n",
            "\n",
            "Train Epoch: 3 [128000/193280 (66%)]\tLoss: 0.007947\n",
            "\n",
            "Train Epoch: 3 [160000/193280 (83%)]\tLoss: 0.002451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:34<01:20, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 3 [192000/193280 (99%)]\tLoss: 0.001081\n",
            "\n",
            "Train Epoch: 4 [0/193280 (0%)]\tLoss: 0.003549\n",
            "\n",
            "Train Epoch: 4 [32000/193280 (17%)]\tLoss: 0.000723\n",
            "\n",
            "Train Epoch: 4 [64000/193280 (33%)]\tLoss: 0.006077\n",
            "\n",
            "Train Epoch: 4 [96000/193280 (50%)]\tLoss: 0.000874\n",
            "\n",
            "Train Epoch: 4 [128000/193280 (66%)]\tLoss: 0.001056\n",
            "\n",
            "Train Epoch: 4 [160000/193280 (83%)]\tLoss: 0.003941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:48<01:14, 12.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 4 [192000/193280 (99%)]\tLoss: 0.000978\n",
            "\n",
            "Train Epoch: 5 [0/193280 (0%)]\tLoss: 0.003309\n",
            "\n",
            "Train Epoch: 5 [32000/193280 (17%)]\tLoss: 0.001262\n",
            "\n",
            "Train Epoch: 5 [64000/193280 (33%)]\tLoss: 0.001949\n",
            "\n",
            "Train Epoch: 5 [96000/193280 (50%)]\tLoss: 0.001550\n",
            "\n",
            "Train Epoch: 5 [128000/193280 (66%)]\tLoss: 0.000796\n",
            "\n",
            "Train Epoch: 5 [160000/193280 (83%)]\tLoss: 0.001400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:01<01:03, 12.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 5 [192000/193280 (99%)]\tLoss: 0.000948\n",
            "\n",
            "Train Epoch: 6 [0/193280 (0%)]\tLoss: 0.001751\n",
            "\n",
            "Train Epoch: 6 [32000/193280 (17%)]\tLoss: 0.004483\n",
            "\n",
            "Train Epoch: 6 [64000/193280 (33%)]\tLoss: 0.000321\n",
            "\n",
            "Train Epoch: 6 [96000/193280 (50%)]\tLoss: 0.008101\n",
            "\n",
            "Train Epoch: 6 [128000/193280 (66%)]\tLoss: 0.001307\n",
            "\n",
            "Train Epoch: 6 [160000/193280 (83%)]\tLoss: 0.001440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:13<00:49, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 6 [192000/193280 (99%)]\tLoss: 0.000760\n",
            "\n",
            "Train Epoch: 7 [0/193280 (0%)]\tLoss: 0.001447\n",
            "\n",
            "Train Epoch: 7 [32000/193280 (17%)]\tLoss: 0.003332\n",
            "\n",
            "Train Epoch: 7 [64000/193280 (33%)]\tLoss: 0.002940\n",
            "\n",
            "Train Epoch: 7 [96000/193280 (50%)]\tLoss: 0.005453\n",
            "\n",
            "Train Epoch: 7 [128000/193280 (66%)]\tLoss: 0.001372\n",
            "\n",
            "Train Epoch: 7 [160000/193280 (83%)]\tLoss: 0.003006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:25<00:36, 12.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 7 [192000/193280 (99%)]\tLoss: 0.012103\n",
            "\n",
            "Train Epoch: 8 [0/193280 (0%)]\tLoss: 0.005146\n",
            "\n",
            "Train Epoch: 8 [32000/193280 (17%)]\tLoss: 0.008139\n",
            "\n",
            "Train Epoch: 8 [64000/193280 (33%)]\tLoss: 0.000348\n",
            "\n",
            "Train Epoch: 8 [96000/193280 (50%)]\tLoss: 0.003690\n",
            "\n",
            "Train Epoch: 8 [128000/193280 (66%)]\tLoss: 0.004538\n",
            "\n",
            "Train Epoch: 8 [160000/193280 (83%)]\tLoss: 0.008579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:37<00:24, 12.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 8 [192000/193280 (99%)]\tLoss: 0.006268\n",
            "\n",
            "Train Epoch: 9 [0/193280 (0%)]\tLoss: 0.003335\n",
            "\n",
            "Train Epoch: 9 [32000/193280 (17%)]\tLoss: 0.001990\n",
            "\n",
            "Train Epoch: 9 [64000/193280 (33%)]\tLoss: 0.002606\n",
            "\n",
            "Train Epoch: 9 [96000/193280 (50%)]\tLoss: 0.001139\n",
            "\n",
            "Train Epoch: 9 [128000/193280 (66%)]\tLoss: 0.001912\n",
            "\n",
            "Train Epoch: 9 [160000/193280 (83%)]\tLoss: 0.002447\n",
            "\n",
            "Train Epoch: 9 [192000/193280 (99%)]\tLoss: 0.001051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [01:49<00:12, 12.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 10 [0/193280 (0%)]\tLoss: 0.005938\n",
            "\n",
            "Train Epoch: 10 [32000/193280 (17%)]\tLoss: 0.001765\n",
            "\n",
            "Train Epoch: 10 [64000/193280 (33%)]\tLoss: 0.002090\n",
            "\n",
            "Train Epoch: 10 [96000/193280 (50%)]\tLoss: 0.002031\n",
            "\n",
            "Train Epoch: 10 [128000/193280 (66%)]\tLoss: 0.002985\n",
            "\n",
            "Train Epoch: 10 [160000/193280 (83%)]\tLoss: 0.006218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:02<00:00, 12.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 10 [192000/193280 (99%)]\tLoss: 0.001298\n",
            "model saved to nn.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, y_val = preprocess(val_df)\n",
        "_, val_dl = create_dls(x_val, y_val)\n",
        "criterion = nn.MSELoss()\n",
        "val_loss, val_r2= test(model, model.device, val_dl, criterion)\n",
        "print(f'Neural Network Validation Mean Squared Error: {val_loss:.6f}')\n",
        "print(f'Neural Network Validation R2: {val_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqZcQqEQV7BA",
        "outputId": "6de81d8e-f51b-46ab-bd05-a081b1ffb35d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Validation Mean Squared Error: 0.000864\n",
            "Neural Network Validation R2: 0.9297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('nn.pth', weights_only=True))\n",
        "# print(\"Model's state_dict:\")\n",
        "# model.state_dict()"
      ],
      "metadata": {
        "id": "mOYlwVqjXoMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95feafcc-be67-46b3-a960-9d332f2afc2a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('L1.weight',\n",
              "              tensor([[-1.7224e-02,  1.5817e-01,  6.4280e-02, -4.4834e-01, -5.1279e-01,\n",
              "                       -2.1299e-03, -3.4860e-03,  5.8696e-02, -1.0740e-03, -1.0833e-03,\n",
              "                       -1.0295e-03, -3.3369e-03,  6.1607e-02,  8.3909e-02],\n",
              "                      [-8.2129e-02,  1.8607e-01, -5.4309e-02, -1.2423e-01, -1.9301e-01,\n",
              "                        1.2961e-02, -7.2939e-02,  1.2869e-01,  2.1684e-01,  5.6681e-02,\n",
              "                        2.2671e-01, -1.1918e-01, -4.6155e-02, -1.6433e-01],\n",
              "                      [ 1.1286e-01,  9.7598e-02,  4.3918e-02, -1.7781e-01, -1.8503e-01,\n",
              "                        1.7688e-03, -9.8405e-04,  3.0680e-02,  2.4066e-04,  1.6771e-03,\n",
              "                       -6.6359e-04,  8.2731e-04,  4.4551e-02,  4.4426e-02],\n",
              "                      [ 1.8135e-01, -1.2530e-01,  9.1653e-02, -2.0359e-02,  1.0247e-01,\n",
              "                        2.5196e-01, -5.1992e-02,  1.1030e-01,  8.4600e-02, -1.4288e-01,\n",
              "                        1.0022e-01, -1.7510e-01,  1.8052e-01,  2.3732e-01],\n",
              "                      [-2.0924e-01, -2.0979e-01,  3.1286e-02,  4.4943e-01,  2.9557e-01,\n",
              "                       -4.0956e-04, -1.8550e-03,  4.8635e-03,  5.5564e-03,  9.3361e-04,\n",
              "                        2.9414e-04,  5.0033e-03,  1.1637e-01,  9.6189e-02],\n",
              "                      [ 1.8823e-01, -1.0646e-01, -2.4112e-02, -2.3278e-01, -5.5117e-02,\n",
              "                        1.2561e-01,  2.1906e-01,  1.4812e-01,  1.5871e-01,  1.3439e-01,\n",
              "                       -5.3085e-02,  2.1219e-01, -2.6689e-01,  1.7364e-01],\n",
              "                      [ 3.6612e-01, -9.6426e-02, -8.1598e-02, -2.7610e-01, -2.1590e-01,\n",
              "                        1.3085e-02,  8.7608e-02,  1.7960e-01, -1.0294e-01,  1.1946e-01,\n",
              "                       -7.2422e-02, -8.4391e-04, -1.0828e-01,  7.0734e-03],\n",
              "                      [ 5.8432e-01, -6.9654e-02, -9.1195e-02,  1.5677e-01,  2.2582e-01,\n",
              "                        4.5351e-02,  2.2881e-02, -1.3414e-01,  1.7312e-01,  4.1435e-02,\n",
              "                        3.5859e-02, -2.9188e-02, -1.6697e-01,  3.0092e-02],\n",
              "                      [ 2.2826e-01,  2.2187e-01,  2.1077e-01,  2.5448e-01, -4.8685e-02,\n",
              "                        8.2075e-02,  1.6846e-01,  1.6327e-01, -3.6973e-02,  3.5328e-02,\n",
              "                        6.2672e-02,  1.2353e-01,  5.2091e-02, -6.1403e-02],\n",
              "                      [-2.2596e-01,  1.8461e-01,  3.6249e-02, -5.0896e-02, -3.5488e-01,\n",
              "                       -7.8718e-02, -3.6388e-02,  6.3315e-02, -4.3488e-02,  4.4875e-02,\n",
              "                        1.4438e-02,  6.3146e-03,  2.4202e-01,  8.5241e-02],\n",
              "                      [ 3.7299e-01, -4.0101e-02, -2.4658e-02, -2.8762e-01, -9.8924e-02,\n",
              "                        8.1007e-04,  4.7154e-04, -1.5353e-01,  3.2655e-03,  8.9064e-03,\n",
              "                        1.4964e-03, -5.4155e-03, -2.2997e-02,  5.3953e-02],\n",
              "                      [ 2.8696e-01, -2.8394e-02, -1.7155e-01, -3.8537e-01,  1.6266e-01,\n",
              "                       -1.3456e-01,  1.2278e-01, -6.5085e-02, -9.4727e-02,  2.5551e-01,\n",
              "                        1.2592e-03,  2.2318e-01,  6.9129e-02, -3.7647e-02],\n",
              "                      [ 6.9650e-02, -9.6922e-02,  6.3705e-02, -4.1547e-01,  1.1158e-01,\n",
              "                       -1.4418e-02, -9.7448e-02,  1.7602e-01,  1.8001e-01, -1.2257e-02,\n",
              "                       -7.6450e-02,  1.2587e-01, -3.5815e-02, -2.0300e-03],\n",
              "                      [-2.2898e-01, -2.2298e-01, -2.4911e-01,  2.7971e-02, -1.6276e-01,\n",
              "                       -3.9376e-02, -4.1828e-02,  5.5636e-03,  2.4081e-01, -1.1763e-01,\n",
              "                       -7.8738e-02,  6.4131e-03,  1.2424e-01,  1.9979e-01],\n",
              "                      [ 3.0091e-01,  2.8017e-01, -1.7480e-02, -2.8144e-01, -5.4633e-01,\n",
              "                        3.9485e-03,  9.6383e-03, -1.7035e-02,  1.3777e-02,  1.5831e-02,\n",
              "                        4.4461e-03, -4.4518e-03, -4.0123e-02, -4.8889e-02],\n",
              "                      [-3.6254e-02, -1.3726e-02,  1.6132e-01,  3.6322e-01,  5.0148e-02,\n",
              "                       -1.2723e-01,  7.4331e-02,  1.2738e-01,  8.3867e-02, -1.1879e-01,\n",
              "                        3.9483e-02, -1.8649e-01, -2.1552e-01,  1.9557e-01],\n",
              "                      [ 1.9180e-01, -3.7805e-01,  4.2405e-02, -3.3171e-01, -1.9999e-01,\n",
              "                        1.7360e-01, -1.0105e-01,  7.2696e-02,  1.7284e-01, -2.2759e-01,\n",
              "                       -4.8346e-02, -7.9840e-02,  1.8561e-01,  5.6187e-02],\n",
              "                      [-1.0347e-01, -2.0281e-01, -2.4859e-01,  1.1797e-01,  6.2341e-02,\n",
              "                       -1.8581e-02, -2.3573e-01,  9.9732e-02,  5.7335e-02,  1.2746e-01,\n",
              "                        1.9078e-01,  1.6326e-01,  1.6250e-02,  1.7038e-01],\n",
              "                      [-7.8882e-02, -2.4435e-01, -1.9374e-01,  1.2018e-02,  1.7661e-01,\n",
              "                        5.5004e-02,  7.1918e-02,  2.2182e-01,  2.2098e-01,  4.2126e-03,\n",
              "                       -8.7616e-03,  2.8156e-03, -2.2088e-01, -2.3800e-01],\n",
              "                      [-2.8392e-01,  4.7119e-02,  5.1479e-03,  3.1843e-01,  4.0130e-01,\n",
              "                        3.1453e-02,  9.3128e-03,  1.2003e-02,  3.7971e-02,  1.6463e-02,\n",
              "                        1.5446e-02,  4.0954e-02,  2.7774e-01,  1.4977e-01],\n",
              "                      [-2.2504e-01,  2.6095e-02,  2.1169e-01, -1.0751e-01, -3.4651e-02,\n",
              "                        5.5603e-02,  5.0484e-02, -9.4287e-02, -2.7532e-02, -6.4050e-02,\n",
              "                        3.0183e-02,  1.9523e-02,  2.7397e-01,  2.4058e-01],\n",
              "                      [ 1.6456e-01,  7.1815e-02,  2.4280e-01, -2.0409e-01,  1.5544e-01,\n",
              "                       -5.8849e-02,  1.5371e-01,  2.3033e-01,  5.2220e-02,  1.8542e-01,\n",
              "                       -1.3375e-01,  1.8675e-01, -1.8255e-01,  6.4296e-02],\n",
              "                      [-4.0892e-01, -7.5700e-02, -1.7802e-03,  2.4499e-01,  1.5150e-01,\n",
              "                       -2.5397e-02,  1.2082e-02,  1.5310e-02, -1.6749e-01,  3.9224e-03,\n",
              "                        5.4372e-04,  6.2052e-03,  2.8336e-02,  3.5967e-02],\n",
              "                      [-3.0261e-01, -1.5750e-01, -1.0083e-02,  2.6051e-01,  7.9878e-02,\n",
              "                        1.4401e-03, -6.3952e-03,  1.2485e-02,  1.1306e-03, -1.7606e-02,\n",
              "                        9.7727e-03,  4.4604e-03,  9.0773e-02,  5.3299e-04],\n",
              "                      [-5.7833e-02, -2.9232e-01,  4.6658e-02,  3.9905e-01,  3.6397e-01,\n",
              "                        7.8631e-03, -2.5290e-03,  3.4743e-02,  8.9569e-03, -3.3828e-04,\n",
              "                        2.7205e-03, -1.1548e-03,  8.3220e-02,  8.6805e-02],\n",
              "                      [-2.0016e-02, -2.1809e-02,  1.0890e-01, -1.9084e-01,  6.4371e-02,\n",
              "                        8.0998e-02, -2.1710e-01,  1.1042e-01,  1.0672e-01,  1.5386e-01,\n",
              "                       -9.4093e-02,  2.1090e-01,  2.1458e-02, -1.8288e-01],\n",
              "                      [-1.9793e-01,  1.0724e-01, -4.9419e-02,  2.1136e-01,  1.3878e-01,\n",
              "                        4.6974e-02,  3.0674e-02, -1.1235e-01,  2.0475e-01,  1.1883e-01,\n",
              "                        1.3062e-01,  1.8556e-02, -6.3107e-02, -6.4649e-02],\n",
              "                      [ 1.3345e-02,  2.6873e-01,  1.2851e-01,  2.4070e-01,  2.6160e-01,\n",
              "                       -3.9873e-02,  1.0136e-01,  1.2752e-01, -1.1567e-02,  5.0632e-02,\n",
              "                        4.1944e-02,  2.0199e-02, -3.0474e-02,  2.6205e-03],\n",
              "                      [ 1.0956e-01,  3.7129e-02, -2.2410e-01,  2.0017e-02, -1.6847e-01,\n",
              "                        9.5059e-02, -1.0007e-01, -7.3011e-02,  5.8720e-02, -1.4365e-01,\n",
              "                       -2.5098e-01, -2.4138e-01,  1.5554e-01, -1.6275e-01],\n",
              "                      [ 2.3020e-01,  5.2854e-02, -8.3531e-03, -3.6647e-01, -2.0133e-01,\n",
              "                       -3.2696e-02, -7.4593e-03, -2.6856e-01, -2.7990e-02,  9.5230e-03,\n",
              "                       -1.1798e-02, -2.0858e-02,  6.3151e-02,  1.3276e-01],\n",
              "                      [ 1.5569e-01,  4.9064e-02, -2.1769e-01,  6.2372e-02,  2.9899e-02,\n",
              "                        9.5250e-02, -1.3887e-01, -1.3266e-01, -3.0170e-02, -1.1201e-01,\n",
              "                        4.3837e-02, -4.6867e-03, -9.9625e-02, -1.6915e-01],\n",
              "                      [ 1.0392e-01, -8.5373e-02, -1.6258e-01, -1.3060e-01,  7.3949e-02,\n",
              "                        6.5022e-03,  2.9874e-02,  3.3982e-01,  1.3397e-01,  5.6064e-02,\n",
              "                       -1.2486e-02, -7.0656e-03, -1.8429e-01, -1.4411e-01],\n",
              "                      [-2.7227e-01,  1.0591e-01,  2.1315e-02, -3.8514e-01, -3.7686e-01,\n",
              "                       -1.5160e-02,  4.1872e-03,  1.5612e-02, -1.5135e-03,  7.7490e-03,\n",
              "                        1.2590e-03, -1.9668e-01,  2.8914e-02,  5.4846e-02],\n",
              "                      [-4.5506e-01, -1.7656e-01,  1.2166e-01,  3.0648e-02, -3.9231e-02,\n",
              "                       -8.2611e-02,  6.8407e-02, -1.9343e-02, -3.3139e-01, -3.2161e-01,\n",
              "                        1.6274e-01, -2.6687e-02, -5.5665e-02, -5.4453e-02],\n",
              "                      [-3.8952e-01,  1.6360e-01,  8.4870e-02,  1.4722e-01,  2.0444e-01,\n",
              "                       -6.2274e-02, -5.9861e-02, -6.6078e-02, -8.5072e-02, -1.6029e-02,\n",
              "                       -2.3942e-02, -3.3956e-02,  1.9321e-01,  1.2671e-01],\n",
              "                      [-2.8432e-01,  5.0736e-02,  5.0245e-02,  8.6324e-03,  4.6309e-02,\n",
              "                        1.4881e-01,  1.5704e-01, -3.1465e-01, -1.4599e-01, -2.5620e-03,\n",
              "                        6.7618e-02,  9.6496e-02,  1.5827e-01,  1.4335e-01],\n",
              "                      [ 4.1325e-01, -1.2437e-01,  5.0804e-02, -2.6887e-02,  1.4786e-01,\n",
              "                       -7.9464e-03,  3.1885e-02,  1.2238e-01, -3.1087e-02,  4.3034e-02,\n",
              "                        4.9968e-02, -1.7605e-01, -6.4235e-02, -1.3394e-01],\n",
              "                      [ 2.1169e-01,  3.0837e-02, -6.0030e-02,  6.0159e-02,  3.5174e-01,\n",
              "                       -1.3367e-01,  2.2248e-02,  1.0324e-01, -7.7742e-02,  7.5230e-02,\n",
              "                       -3.8149e-02,  1.7820e-01,  2.1391e-01,  2.1899e-01],\n",
              "                      [-2.6047e-01,  2.5198e-01, -3.3386e-01,  6.7900e-02,  9.1878e-02,\n",
              "                       -1.1060e-01, -2.2682e-01, -9.5007e-02, -1.5533e-01, -3.3201e-02,\n",
              "                        2.6452e-02, -1.1935e-01,  1.2285e-01, -2.2399e-01],\n",
              "                      [ 2.3774e-01, -1.3780e-01, -4.0412e-02, -1.9832e-02,  1.9642e-01,\n",
              "                       -2.4498e-02, -2.5588e-02, -2.6997e-02,  1.4660e-02, -3.4265e-02,\n",
              "                       -4.9367e-02, -1.7964e-02, -1.0186e-01, -2.8334e-02],\n",
              "                      [ 5.0377e-02,  1.1458e-01,  1.1550e-02,  2.8878e-01,  2.4557e-01,\n",
              "                        9.0797e-02,  2.0066e-01, -1.2480e-01,  1.0252e-01,  7.6812e-02,\n",
              "                       -9.5288e-02,  1.9596e-01,  7.7558e-02,  2.2028e-01],\n",
              "                      [-2.1303e-01, -4.8012e-02, -1.8332e-01,  5.4846e-02, -1.6754e-01,\n",
              "                        3.8347e-02,  1.9577e-01, -2.1374e-01,  8.7696e-02, -1.3837e-01,\n",
              "                        1.8542e-02, -2.4037e-01, -1.3793e-01, -1.3562e-01],\n",
              "                      [-8.0691e-02, -1.5466e-01, -4.7304e-02,  3.7232e-01,  3.8191e-01,\n",
              "                       -1.6257e-02, -6.9806e-03,  4.3774e-03, -9.1046e-03,  3.0325e-03,\n",
              "                       -4.3831e-03,  3.4487e-03, -2.4659e-02, -1.0955e-01],\n",
              "                      [ 1.9291e-02, -2.4969e-01,  1.3835e-01,  2.0682e-01,  2.9827e-01,\n",
              "                        8.5775e-02, -7.9970e-02,  4.4866e-02, -4.9283e-02,  5.4208e-02,\n",
              "                        2.7624e-02,  4.1998e-02,  4.5643e-02,  1.8821e-01],\n",
              "                      [-1.3440e-01, -3.1591e-01,  2.6122e-02, -3.2177e-02,  5.1191e-02,\n",
              "                       -1.4098e-01, -1.0728e-01,  1.5892e-01,  8.3167e-02, -2.8710e-01,\n",
              "                       -9.6602e-03, -2.3709e-01, -1.5543e-02,  1.5561e-01],\n",
              "                      [-8.9534e-02, -1.6541e-01,  1.2870e-01,  3.1971e-02, -4.8412e-02,\n",
              "                       -1.4131e-02,  9.8623e-02, -2.1947e-01, -5.4953e-02, -8.1743e-02,\n",
              "                       -9.0844e-03, -5.2731e-02,  2.1378e-01, -2.2598e-01],\n",
              "                      [-6.7604e-02,  5.2471e-01,  4.6580e-04,  2.5024e-01,  2.7930e-01,\n",
              "                        2.0560e-02,  1.3286e-02, -2.7443e-02,  2.6748e-02,  9.4077e-02,\n",
              "                        9.9806e-03,  2.0273e-02, -4.5198e-02, -6.9564e-02],\n",
              "                      [-3.5014e-02, -2.2975e-01, -3.6921e-01,  7.9949e-02, -1.8583e-02,\n",
              "                        6.3195e-02,  7.1585e-02,  8.8786e-02,  2.1599e-01, -1.2160e-01,\n",
              "                       -1.0319e-01,  7.1395e-02,  1.8942e-01, -1.9002e-01],\n",
              "                      [ 9.6761e-03,  3.2778e-01,  2.9142e-02, -2.1094e-02, -7.3407e-02,\n",
              "                        8.6659e-02,  1.0643e-01, -6.6943e-03,  2.7376e-01,  2.4035e-01,\n",
              "                        1.2657e-01,  1.4796e-02,  6.3014e-02, -1.5441e-03],\n",
              "                      [ 2.7779e-01,  1.4936e-01, -1.0981e-01, -3.0464e-01, -2.3356e-01,\n",
              "                       -3.9590e-03, -2.4236e-02, -3.6879e-02,  1.2942e-03, -1.1600e-02,\n",
              "                       -8.4087e-03, -1.0749e-02, -1.0160e-01, -1.2823e-01],\n",
              "                      [ 2.2703e-01,  2.7497e-01,  1.1707e-01, -1.5136e-01, -2.6436e-01,\n",
              "                        1.4038e-01,  9.5267e-02,  8.5511e-02,  6.4791e-02, -1.3943e-01,\n",
              "                        9.8895e-02,  6.0455e-02, -8.5745e-02, -1.7397e-01],\n",
              "                      [ 2.3565e-01, -1.8253e-01,  2.5135e-01, -2.4440e-01,  1.0116e-01,\n",
              "                       -1.2472e-01,  9.8301e-02, -2.0086e-01, -1.9532e-01,  1.5322e-01,\n",
              "                       -1.3240e-01,  1.5142e-01, -2.3594e-01,  5.5728e-02],\n",
              "                      [ 2.3039e-02,  8.5856e-03,  2.2187e-02,  2.2685e-01, -1.2832e-01,\n",
              "                        9.5753e-02,  4.9699e-02,  1.8878e-01,  2.2595e-01,  1.9800e-01,\n",
              "                        2.2436e-01,  1.8412e-01, -2.8613e-03, -2.3817e-01],\n",
              "                      [-2.5957e-01, -2.8496e-01, -3.1527e-01,  1.0871e-01,  1.3336e-01,\n",
              "                       -1.3081e-01, -2.2824e-01,  7.7293e-02, -1.5081e-01, -1.9756e-01,\n",
              "                        2.4089e-01, -5.5392e-02, -3.3714e-02,  1.7325e-01],\n",
              "                      [ 2.3976e-01,  2.2396e-01, -3.9105e-03, -4.9619e-01, -1.3092e-01,\n",
              "                       -5.0568e-03,  1.4014e-03, -5.9002e-03, -2.4155e-03, -3.2241e-04,\n",
              "                       -9.0805e-05, -1.3248e-05, -6.4681e-03, -2.0711e-03],\n",
              "                      [-8.4232e-02,  2.8877e-01, -2.6777e-02,  3.4365e-01,  2.7571e-01,\n",
              "                        9.3148e-02, -7.1990e-02, -1.3284e-01,  3.2909e-02, -1.2257e-01,\n",
              "                       -1.0605e-01, -1.9943e-02, -8.2152e-02, -6.3892e-02],\n",
              "                      [-4.9897e-01,  6.3349e-03,  4.1015e-02,  2.5469e-01, -7.2574e-02,\n",
              "                       -3.9951e-02,  5.0555e-02,  7.7131e-02, -7.4489e-02,  1.7641e-02,\n",
              "                       -8.0741e-03,  6.3154e-02,  1.7783e-02,  1.2118e-01],\n",
              "                      [ 2.8652e-01, -1.4895e-01,  5.2104e-02,  8.0103e-02,  1.3337e-01,\n",
              "                        3.5500e-02,  3.3322e-02, -8.5745e-02,  6.6855e-02, -3.7182e-02,\n",
              "                       -1.3830e-01,  1.9651e-03,  4.1175e-03, -1.6397e-01],\n",
              "                      [-7.3898e-02,  9.4605e-02, -4.2780e-02, -6.9263e-02, -2.7759e-01,\n",
              "                        2.9385e-02,  5.7639e-02, -5.2563e-04,  1.2427e-02,  7.7162e-02,\n",
              "                        1.6157e-01, -6.2792e-03, -2.8880e-01, -1.8849e-01],\n",
              "                      [-4.2196e-02,  1.3353e-01, -2.3058e-01, -1.0518e-01, -2.9598e-02,\n",
              "                       -1.0447e-01, -1.2490e-01, -6.9767e-02, -6.5639e-02,  3.2545e-02,\n",
              "                       -5.0864e-02, -7.9167e-02,  2.9664e-01,  2.3177e-01],\n",
              "                      [-2.3096e-01,  2.6359e-01, -1.6237e-01, -3.9875e-01, -7.0623e-02,\n",
              "                       -2.2482e-02, -4.8384e-02,  2.2618e-01, -4.0853e-02, -9.1619e-02,\n",
              "                       -5.2032e-04,  1.7482e-01,  2.6828e-02,  1.8546e-01],\n",
              "                      [-8.4842e-02,  3.2844e-02, -1.3188e-01, -1.9914e-01,  9.0554e-02,\n",
              "                       -2.0331e-01, -1.3676e-01,  1.9456e-01,  1.3066e-01,  1.6310e-01,\n",
              "                       -1.1137e-02, -1.8474e-01, -4.9208e-03,  1.4744e-01],\n",
              "                      [-3.0835e-02, -3.2800e-01,  3.2660e-02,  8.9009e-02,  2.2941e-01,\n",
              "                       -2.7701e-02, -1.6851e-03, -1.5396e-01, -4.0067e-02,  1.1648e-01,\n",
              "                        2.2746e-02, -1.1067e-02,  1.5503e-01,  2.5350e-01],\n",
              "                      [ 6.4361e-03,  1.2637e-01,  2.7749e-01, -9.2065e-02, -1.8147e-01,\n",
              "                        2.1194e-01,  1.0148e-01,  9.4914e-02,  2.0760e-01,  7.5122e-02,\n",
              "                       -7.3018e-02, -2.5718e-01,  1.0487e-01,  1.5457e-01]], device='cuda:0')),\n",
              "             ('L1.bias',\n",
              "              tensor([-0.2747,  0.1361, -0.2572,  0.0519, -0.0033,  0.0680,  0.0164, -0.0582,\n",
              "                       0.0945, -0.0081, -0.1738,  0.2515,  0.1740, -0.1858, -0.1759, -0.1335,\n",
              "                       0.0915,  0.2740,  0.2159, -0.1011,  0.0158,  0.1172,  0.0766,  0.2701,\n",
              "                       0.0628,  0.2472, -0.0244,  0.0465,  0.1694,  0.0539,  0.0895, -0.0828,\n",
              "                      -0.1153, -0.0474,  0.1047,  0.0525,  0.0669,  0.0549, -0.0074, -0.0924,\n",
              "                      -0.0686, -0.1252,  0.2851,  0.3206, -0.2395, -0.1645, -0.1114, -0.1980,\n",
              "                      -0.2812, -0.0826,  0.1992,  0.2838,  0.0064, -0.2057, -0.2244, -0.0217,\n",
              "                       0.0035,  0.2795,  0.2907,  0.1208,  0.0005, -0.0326,  0.1619,  0.3173],\n",
              "                     device='cuda:0')),\n",
              "             ('L2.weight',\n",
              "              tensor([[ 0.0627,  0.0117,  0.1631,  0.0203,  0.1524, -0.0148,  0.0149, -0.0561,\n",
              "                        0.0096,  0.0498, -0.0321, -0.0201,  0.0023,  0.0042,  0.1654,  0.0043,\n",
              "                        0.0116, -0.0155,  0.0234, -0.0782,  0.0735, -0.0114,  0.0513, -0.1460,\n",
              "                       -0.1999, -0.0139,  0.0149,  0.0230, -0.0025,  0.0427,  0.0066, -0.0228,\n",
              "                       -0.0492,  0.0073, -0.0494, -0.0147, -0.0307,  0.0282,  0.0049,  0.0208,\n",
              "                        0.0313, -0.0078,  0.1500,  0.0704,  0.0050,  0.0034, -0.0985, -0.0034,\n",
              "                        0.0353, -0.0705, -0.0372, -0.0021, -0.0062,  0.0044,  0.1289,  0.0152,\n",
              "                       -0.0382, -0.0066, -0.0228, -0.0127,  0.0105,  0.0027, -0.0486, -0.0112]],\n",
              "                     device='cuda:0')),\n",
              "             ('L2.bias', tensor([-0.0334], device='cuda:0')),\n",
              "             ('bn1.weight',\n",
              "              tensor([0.9870, 0.8450, 1.0514, 0.9259, 1.0175, 0.8584, 0.8638, 0.9613, 0.9052,\n",
              "                      0.8900, 0.8933, 0.8805, 0.8709, 0.8275, 1.1296, 0.7770, 0.9252, 0.8577,\n",
              "                      0.9082, 1.0068, 0.9033, 0.9015, 0.9475, 1.0532, 1.0648, 0.8920, 0.9198,\n",
              "                      0.8873, 0.8722, 0.8690, 0.9043, 0.9532, 0.9087, 0.8754, 0.9303, 0.8953,\n",
              "                      0.8704, 0.9450, 0.8743, 0.8942, 0.9094, 0.8670, 1.0972, 0.9173, 0.8581,\n",
              "                      0.8044, 1.0419, 0.8566, 0.9586, 0.9287, 0.9444, 0.8627, 0.8871, 0.8775,\n",
              "                      1.0006, 0.9233, 0.8982, 0.8571, 0.9134, 0.9395, 0.8857, 0.8560, 0.9802,\n",
              "                      0.8484], device='cuda:0')),\n",
              "             ('bn1.bias',\n",
              "              tensor([ 0.0016,  0.0044,  0.0082,  0.0035,  0.0046, -0.0043,  0.0060,  0.0005,\n",
              "                       0.0053,  0.0048, -0.0042, -0.0051,  0.0051,  0.0033,  0.0024,  0.0035,\n",
              "                       0.0015, -0.0067, -0.0018, -0.0016,  0.0069,  0.0020,  0.0022, -0.0042,\n",
              "                      -0.0049, -0.0039,  0.0004,  0.0008, -0.0012,  0.0065,  0.0009, -0.0018,\n",
              "                       0.0032,  0.0006, -0.0041, -0.0031, -0.0056,  0.0025,  0.0011,  0.0022,\n",
              "                       0.0029, -0.0011,  0.0023,  0.0040,  0.0025,  0.0026, -0.0030,  0.0014,\n",
              "                       0.0035, -0.0032,  0.0009, -0.0029,  0.0014,  0.0032,  0.0064,  0.0025,\n",
              "                      -0.0042, -0.0057, -0.0031, -0.0005,  0.0032, -0.0025, -0.0019, -0.0045],\n",
              "                     device='cuda:0')),\n",
              "             ('bn1.running_mean',\n",
              "              tensor([2.3777e-03, 1.5665e-01, 2.6168e-03, 4.4812e-01, 1.2347e-01, 3.5152e-01,\n",
              "                      1.0985e-01, 2.4865e-01, 7.9906e-01, 1.1395e-01, 1.8628e-02, 3.8626e-01,\n",
              "                      2.4011e-01, 1.5378e-03, 4.6596e-02, 8.7259e-02, 1.0394e-01, 2.8041e-01,\n",
              "                      7.2992e-02, 2.4789e-01, 2.7441e-01, 5.7273e-01, 3.9836e-02, 1.5702e-01,\n",
              "                      2.0955e-01, 3.1154e-01, 7.4966e-02, 5.2267e-01, 2.4902e-02, 8.4916e-02,\n",
              "                      2.1958e-02, 4.6732e-02, 2.0553e-04, 1.6469e-03, 1.8312e-01, 1.8139e-01,\n",
              "                      2.2098e-01, 5.7134e-01, 4.3982e-03, 9.4690e-03, 4.5858e-01, 3.4784e-05,\n",
              "                      2.3989e-01, 5.8366e-01, 8.8330e-05, 3.5973e-03, 2.7163e-01, 3.7499e-03,\n",
              "                      1.9499e-01, 1.4132e-02, 5.1672e-01, 2.6748e-01, 3.9094e-01, 8.3468e-04,\n",
              "                      2.5957e-02, 8.5105e-02, 6.0726e-02, 2.9068e-01, 1.3202e-01, 1.3836e-01,\n",
              "                      1.4133e-01, 2.5670e-02, 2.2028e-01, 6.7093e-01], device='cuda:0')),\n",
              "             ('bn1.running_var',\n",
              "              tensor([1.8006e-04, 2.5868e-02, 1.5910e-04, 6.1120e-02, 2.1357e-02, 5.4063e-02,\n",
              "                      2.0063e-02, 5.2628e-02, 6.3952e-02, 1.8036e-02, 2.0465e-03, 5.5651e-02,\n",
              "                      2.8717e-02, 1.1898e-04, 8.3133e-03, 2.0363e-02, 2.1706e-02, 4.5217e-02,\n",
              "                      1.4433e-02, 4.3830e-02, 4.3176e-02, 7.1994e-02, 4.9408e-03, 1.7693e-02,\n",
              "                      3.0429e-02, 3.4342e-02, 9.9932e-03, 4.2616e-02, 4.6421e-03, 1.4169e-02,\n",
              "                      3.1246e-03, 8.5099e-03, 9.3012e-06, 1.7590e-04, 2.9967e-02, 3.7848e-02,\n",
              "                      3.2797e-02, 5.5032e-02, 8.0620e-04, 9.5575e-04, 6.4072e-02, 3.0529e-06,\n",
              "                      2.5893e-02, 4.0193e-02, 3.6200e-06, 3.8032e-04, 5.2613e-02, 5.2049e-04,\n",
              "                      3.1583e-02, 1.8862e-03, 4.4506e-02, 5.3306e-02, 6.1590e-02, 1.2386e-04,\n",
              "                      3.1646e-03, 1.5821e-02, 1.0039e-02, 3.1182e-02, 2.3176e-02, 3.0377e-02,\n",
              "                      2.8531e-02, 4.8468e-03, 3.4183e-02, 6.4213e-02], device='cuda:0')),\n",
              "             ('bn1.num_batches_tracked', tensor(60400, device='cuda:0')),\n",
              "             ('bn2.weight', tensor([0.0979], device='cuda:0')),\n",
              "             ('bn2.bias', tensor([0.0605], device='cuda:0')),\n",
              "             ('bn2.running_mean', tensor([-0.0242], device='cuda:0')),\n",
              "             ('bn2.running_var', tensor([0.1962], device='cuda:0')),\n",
              "             ('bn2.num_batches_tracked', tensor(60400, device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA, Lasso & Linear Regression - Katelyn"
      ],
      "metadata": {
        "id": "KV9NQxxkBrNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "X_train = pca.fit_transform(x_tr)\n",
        "X_test = pca.transform(x_val)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "print(explained_variance)\n"
      ],
      "metadata": {
        "id": "Qs-FDMoSBvXf",
        "outputId": "79b03d01-0876-42ef-dd03-5e3b55db985b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10205183 0.10191195]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#From Sklearn --> Lasso documentation\n",
        "\n",
        "#Setting alpha\n",
        "lasso = Lasso(alpha=0.00001)\n",
        "\n",
        "#Fitting to training data\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "#making y predictions based on the X_test, given by the PCA\n",
        "y_pred = lasso.predict(X_test)\n",
        "\n",
        "#Getting the MSE\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "print(\"Coefficients:\", lasso.coef_)\n",
        "#very low lasso coefficents"
      ],
      "metadata": {
        "id": "_nXR5cexENNO",
        "outputId": "4c4197b2-6320-4053-b554-c7e27519fce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.012236981126572908\n",
            "Coefficients: [ 0.01265718 -0.00163292]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize LDA and fit the model\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = linreg.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "#This does very well, but the other methods are preferable for exploring.\n",
        "print('train r2:', r2_score(y_tr, y_train))"
      ],
      "metadata": {
        "id": "Ld6SL5soFShI",
        "outputId": "335573d5-c955-4322-9f86-e020d789a6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.012236947492410348\n",
            "train r2: 0.9901529624802171\n"
          ]
        }
      ]
    }
  ]
}